<<<<<<< HEAD
{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"riiid-2020.ipynb","private_outputs":true,"provenance":[{"file_id":"https://github.com/CalebEverett/riiid-2020/blob/master/riiid-2020.ipynb","timestamp":1604714801726}],"collapsed_sections":["8QCO0cr_juQA","88t93RZzj982","3I6-yy4QBxlR","cs6bXr35juQM","BjTuu8CJjuQT","QhPzQmvUjuQV","GOpOrtr9juQY","Ouoo1oQCjuQm","CfKY_WsvjuQp","YTG_h2a2juQy","zO6GM_CLjuQ5"],"toc_visible":true,"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"orpoYGXZdptj"},"source":["!curl ipinfo.io"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N4lHWTOFrRgT"},"source":["# <hide-input>\n","def show_version_history():\n","    from IPython.display import HTML\n","    style_header = 'mui--align-bottom mui--bg-primary mui--text-light mui--text-center'\n","    style_cell = 'mui--align-top mui--text-center'\n","\n","    # print(('\\n').join(list(map(make_li, sorted(dtypes.keys())))))\n","\n","    html_str = f\"\"\"\n","    <link href=\"//cdn.muicss.com/mui-0.10.3/css/mui.min.css\" rel=\"stylesheet\" type=\"text/css\" />\n","    <div class=\"mui-container-fluid\">\n","        <h2>Version History</h2>\n","        <div style=\"max-width:1016px\" class=\"mui-row\">\n","            <div class=\"mui-col-8\">\n","                <table class=\"mui-table mui-table--bordered\">\n","                    <tr>\n","                        <th width=\"12%\" class=\"{style_header}\">Version</th>\n","                        <th width=\"12%\" class=\"{style_header}\">Date</th>\n","                        <th width=\"12%\" class=\"{style_header}\">Local CV</th>\n","                        <th width=\"12%\" class=\"{style_header}\">Public<br>Leaderboard</th>\n","                        <th class=\"{style_header} mui--align-bottom mui--bg-primary\n","                            mui--text-dark mui--text-left\">Notes</th>                    \n","                    </tr>\n","                    <tr>\n","                        <td class=\"{style_cell}\">58</td>\n","                        <td class=\"{style_cell}\">2020-11-15</td>\n","                        <td class=\"{style_cell}\">0.756</td>\n","                        <td class=\"{style_cell}\">0.762</td>\n","                        <td><ul>\n","                                <li>Completed submission pipeline with minimal feature set:\n","                                    <ul>\n","                                        <li><code>answered_correctly_content_id_cumsum</code></li>\n","                                        <li><code>answered_correctly_cumsum</code></li>\n","                                        <li><code>answered_correctly_cumsum_pct</code></li>\n","                                        <li><code>answered_incorrectly_content_id_cumsum</code></li>\n","                                        <li><code>answered_incorrectly_cumsum</code></li>\n","                                        <li><code>part</code></li>\n","                                        <li><code>part_correct_pct</code></li>\n","                                        <li><code>question_id_correct_pct</code></li>\n","                                        <li><code>tag__0</code></li>\n","                                        <li><code>tag__0_correct_pct</code></li>\n","                                        <li><code>task_container_id</code></li>\n","                                        <li><code>timestamp</code></li>\n","                                    </ul>\n","                                </li>\n","                                <li>Changed logic on roll sum to be over trailing\n","                                    rows preceding the current <code>task_container_id</code> instead\n","                                    of over trailing task containers\n","                                    (expensive)\n","                                </li>\n","                            </ul>\n","                        </td>\n","                    </tr>\n","                    <tr>\n","                        <td class=\"{style_cell}\">53</td>\n","                        <td class=\"{style_cell}\">2020-11-07</td>\n","                        <td class=\"{style_cell}\">0.761</td>\n","                        <td class=\"{style_cell}\">--</td>\n","                        <td><ul><li>Housekeeping:\n","                                    <ul>\n","                                        <li>Consolidated notebook and modules in single repo</li>\n","                                        <li>Streamlined Colab repo workflow using Drive</>\n","                                        <li>Included modules in notebook when pushed to Kaggle</li>\n","                                        <li>Eliminated CONFIG requirement when run in Kaggle</li>\n","                                    </ul>\n","                                </li>\n","                            </ul>\n","                        </td>\n","                    </tr>\n","                    <tr>\n","                        <td class=\"{style_cell}\">40</td>\n","                        <td class=\"{style_cell}\">2020-11-05</td>\n","                        <td class=\"{style_cell}\">0.761</td>\n","                        <td class=\"{style_cell}\">--</td>\n","                        <td>\n","                            <ul>\n","                                <li>Features added:\n","                                    <ul>\n","                                        <li><code>answered_correctly_content_id_cumsum</code></li>\n","                                        <li><code>answered_correctly_content_id_cumsum_pct</code></li>\n","                                        <li><code>answered_correctly_cumsum10</code></li>\n","                                        <li><code>answered_correctly_cumsum_pct</code></li>\n","                                        <li><code>answered_correctly_rollsum_pct</code></li>\n","                                        <li><code>answered_incorrectly_content_id_cumsum</code></li>\n","                                        <li><code>lectures_cumcount</code></li>\n","                                        <li><code>prior_question_elapsed_time_rollavg</code></li>\n","                                    </ul>\n","                                </li>\n","                                <li>Single model, single fold</li>\n","                                <li>No public leaderboard - efficient inference in progress</li>\n","                                <li>Refactored code to move queries and helper functions into\n","                                    separate modules</li>\n","                                <li>Completed set up to commit code to Github from Colab and</li>\n","                                <li>Completed set up to push kernels to Kaggle from Colab</li>\n","                            </ul>\n","                        </td>\n","                    </tr>\n","                    <tr>\n","                        <td class=\"{style_cell}\">37</td>\n","                        <td class=\"{style_cell}\">2020-11-04</td>\n","                        <td class=\"{style_cell}\">0.751</td>\n","                        <td class=\"{style_cell}\">0.748</td>\n","                        <td>\n","                            <ul>\n","                                <li>Features added:\n","                                    <ul>\n","                                        <li><code>answered_correctly_cumsum</code></li>\n","                                        <li><code>answered_correctly_rollsum</code></li>\n","                                        <li><code>answered_incorrectly_cumsum</code></li>\n","                                        <li><code>answered_incorrectly_rollsum</code></li>\n","                                        <li><code>part</code></li>\n","                                        <li><code>part_correct_pct</code></li>\n","                                        <li><code>question_id_correct_pct</code></li>\n","                                        <li><code>tag__0</code></li>\n","                                        <li><code>tag__0_correct_pct</code></li>\n","                                    </ul>\n","                                </li>\n","                                <li>Single model, single fold</li>\n","                                <li>Model for public leaderboard didn't include\n","                                    rolling features - still working out how to\n","                                    efficiently calculate for inference</li>\n","                            </ul>\n","                        </td>\n","                    </tr>\n","                </table>\n","            </div>\n","        </div>\n","        <p>\n","            <a href=\"https://colab.research.google.com/github/CalebEverett/riiid_2020/blob/master/riiid-2020.ipynb\" target=\"_blank\" rel=\"nofollow\">\n","            <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n","        </p>\n","    </div>\n","    \"\"\"\n","\n","    html = HTML(html_str)\n","    display(html)\n","show_version_history()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8QCO0cr_juQA"},"source":["## Intro"]},{"cell_type":"markdown","metadata":{"id":"L1mQ0DiRnfer"},"source":["This kernel is an end to end pipeline that uses BigQuery to store data and perform feature engineering, and trains a model using XGBoost. I was resorting to breaking up tables and still waiting a long time to see the results of my analysis and to process my engineered features, so I decided to learn about BigQuery. This kernel is the current state of my setup, which is working very well. It is much faster than my previous local setup, even with having to download files. It also is making it easier to keep the structure of the data and and code clean, which in turn makes it easier to stay focused on thinking about and executing ideas without getting bogged down waiting for things to finish or wading through extraneous processing code.\n","\n","I've attempted to put  this book together in such a way that somebody else can fork it, update a few environment variables, run it and then be in the game engineering features and improving the model. The only requirements are a GCP project and storage bucket. Other than that, it is turn key, starting with creating a BigQuery dataset and ending with a saved model and two feature tables that get uploaded to a Kaggle dataset where they are used in a separate kernel to make predictions and submit to the competition api.\n","\n","A couple of cool features:\n","* Uses the gcs version of the competition datset to create a dataset and upload to BigQuery in around a minute\n","* Transformations get run on the entire train table at once and run in under 10 minutes\n","* Feature engineering gets done on a sample of the train table, taking advantage of BigQuery' graphical query editing interface that includes tab completion, syntax checking and the ability to run queries and inspect results\n","* Stores queries as methods on a dedicated class, where they can be easily reused\n","* Dtypes for local dataframes, schema for BigQuery tables and all tranformations are maintained locally so that the transformed tables can be recreated from the original competition dataset files automatically at any time (see description of workflow below to continue with this practice)\n","* Exports to gcs using temporary tables created by BigQuery avoiding unnecessary storage and wasted time rerunning and exporting duplicate queries\n","* Separate [submission kernel](https://www.kaggle.com/calebeverett/riiid-submit) uses sqlite3 to achieve sub two hour submission times while maintaining state for questions, users and user-content (80+ million rows)\n","\n","I've engineered a few features as a starting point to demonstrate how additional features can be efficiently developed and processed, including:\n","* Cumulative and rolling sums of questions answered correctly and incorrectly by user\n","* Percent of questions answered correctly by question id, part and the first question tag\n","\n","The model is also just a starting point, with a first pass at a train/validation split and no hyperparameter tuning. I have included some basic diagnostics on both the train/validtion split and model performance as a starting place for further development. Trained on a small subset of the overall training data with a small number of engineered features, it is producing a local validation AUC score of around 0.75 and slighly less than that on the public leaderboard.\n","\n","I have the table creation and transformation functions set to not run, but you can set them to run, by changing the flags to `True` for:\n","* Loading tables - one flag for the questions table and another for the train and lectures tables\n","* Updating the schemas in BigQuery\n","* Performing the transformations"]},{"cell_type":"markdown","metadata":{"id":"savju5R9juQB"},"source":["## Resources\n","* [BigQuery Console](https://console.cloud.google.com/bigquery)\n","* [Python Client for Google BigQuery](https://googleapis.dev/python/bigquery/latest/index.html)\n","* [Analytic function concepts in Standard SQL](https://cloud.google.com/bigquery/docs/reference/standard-sql/analytic-function-concepts)\n","* [XGBoost Documentation](https://xgboost.readthedocs.io/en/latest/index.html)\n","* [Storge Client](https://googleapis.dev/python/storage/latest/client.html)\n","* [pandas documentation](https://pandas.pydata.org/docs/)\n","* [Plotly Python Open Source Graphing Library](https://plotly.com/python/)\n","* [PEP 8 -- Style Guide for Python Code](https://www.python.org/dev/peps/pep-0008/)\n","* [Comet.ml Experiment API](https://www.comet.ml/docs/python-sdk/Experiment/)"]},{"cell_type":"markdown","metadata":{"id":"88t93RZzj982"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"lvWug_IF5J_E"},"source":["git.push()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKe4S7M4nbSU"},"source":["# <hide-input>\n","%load_ext autoreload\n","%autoreload 2\n","\n","from datetime import datetime\n","import gc\n","import json\n","import os\n","from pathlib import Path\n","import re\n","import subprocess\n","import sys\n","import time\n","\n","import ipywidgets as widgets\n","from google.cloud import storage, bigquery\n","from google.cloud.bigquery import SchemaField\n","import numpy as np\n","import pandas as pd\n","from tqdm.notebook import tqdm\n","\n","BUCKET = 'riiid-caleb'\n","DATASET = 'data'\n","LOCATION = 'US'\n","KAGGLE_SUBMIT_DATASET = 'riiid-submission-private'\n","PROJECT = 'riiid-caleb'\n","REPO = 'riiid_2020'\n","NOT_KAGGLE = os.getenv('KAGGLE_URL_BASE') is None\n","\n","if NOT_KAGGLE:\n","    from google.colab import drive\n","    DRIVE = Path('/content/drive/My Drive')\n","    if not DRIVE.exists():\n","        drive.mount(str(DRIVE.parent))\n","    sys.path.append(str(DRIVE))\n","    g_creds_path = 'credentials/riiid-caleb-faddd0c9d900.json'\n","    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = str(DRIVE/g_creds_path)\n","\n","bucket = storage.Client(project=PROJECT).get_bucket(BUCKET)\n","dataset = bigquery.Dataset(f'{PROJECT}.{DATASET}')\n","bq_client = bigquery.Client(project=PROJECT, location=LOCATION)\n","\n","if NOT_KAGGLE:\n","    CONFIG = json.loads(bucket.get_blob('config.json').download_as_string())\n","    os.environ = {**os.environ, **CONFIG}\n","    from riiid_2020.utilities import check_packages, Git\n","    from riiid_2020.bqhelpers import BQHelper\n","    from riiid_2020.queries import Queries\n","    \n","    git = Git(REPO, CONFIG.get('GIT_USERNAME'), CONFIG.get('GIT_PASSWORD'),\n","              CONFIG.get('EMAIL'), DRIVE)\n","\n","    packages = {\n","        'comet-ml': '3.2.5',\n","        'gcsfs': '0.7.1',\n","        'kaggle': '1.5.9',\n","        'plotly': '4.12.0',\n","        'xgboost': '1.2.0',\n","    }\n","    check_packages(packages)\n","\n","    from comet_ml import APIExperiment, Experiment\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","    kaggle_api = KaggleApi()\n","    kaggle_api.authenticate()\n","\n","import lightgbm as lgb\n","import plotly\n","import plotly.express as px\n","from sklearn.metrics import roc_auc_score\n","from sklearn.preprocessing import MultiLabelBinarizer\n","import xgboost as xgb\n","pd.options.plotting.backend = 'plotly'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3I6-yy4QBxlR"},"source":["## Modules\n","Included in notebook for convenience when in a Kaggle kernel. Github repo [here](https://github.com/CalebEverett/riiid_2020)."]},{"cell_type":"code","metadata":{"id":"--uRkD6w0EhS"},"source":["# <include-bqhelpers.py><hide-input>"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dTP7zTkV0qhK"},"source":["# <include-queries.py><hide-input>"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FWx9otMx1O2Y"},"source":["# <include-utilities.py><hide-input>"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r4nP2GeV09FG"},"source":["# <include-config.json><hide-input><hide-output>"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WO6DVIxuQydR"},"source":["Q = Queries(DATASET)\n","bqh = BQHelper(bucket, DATASET, bq_client)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cs6bXr35juQM"},"source":["## Create BigQuery Dataset"]},{"cell_type":"code","metadata":{"trusted":true,"id":"MVloHU3wjuQQ"},"source":["if False:\n","    delete_contents=False\n","    bq_client.delete_dataset(DATASET, delete_contents=delete_contents)\n","    print(f'Dataset {dataset.dataset_id} deleted from project {dataset.project}.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"y2-E_hTejuQO"},"source":["try:\n","    dataset = bq_client.get_dataset(dataset.dataset_id)\n","    print(f'Dataset {dataset.dataset_id} already exists '\n","          f'in location {dataset.location} in project {dataset.project}.')\n","except:\n","    dataset = bq_client.create_dataset(dataset)\n","    print(f'Dataset {dataset.dataset_id} created '\n","          f'in location {dataset.location} in project {dataset.project}.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HItb6CWGjuQS"},"source":["## Load Tables"]},{"cell_type":"markdown","metadata":{"id":"BjTuu8CJjuQT"},"source":["### Dataframe dtypes"]},{"cell_type":"code","metadata":{"trusted":true,"id":"8dxMzeCsjuQT"},"source":["# <hide-input>\n","dtypes_orig = {\n","    'lectures': {\n","        'lecture_id': 'uint16',\n","        'tag': 'uint8',\n","        'part': 'uint8',\n","        'type_of': 'str',\n","    },\n","    'questions': {\n","        'question_id': 'uint16',\n","        'bundle_id': 'uint16',\n","        'correct_answer': 'uint8',\n","        'part': 'uint8',\n","        'tags': 'str',\n","        \n","    },\n","    'train': {\n","        'row_id': 'int64',\n","        'timestamp': 'int64',\n","        'user_id': 'int32',\n","        'content_id': 'int16',\n","        'content_type_id': 'int8',\n","        'task_container_id': 'int16',\n","        'user_answer': 'int8',\n","        'answered_correctly': 'int8',\n","        'prior_question_elapsed_time': 'float32', \n","        'prior_question_had_explanation': 'bool',\n","    }\n","    \n","}\n","\n","dtypes_new = {\n","    'lectures': {},\n","    'questions': {},\n","    'train': {\n","        'ql_id': 'int16',\n","        'fold': 'int8',\n","        'lectures_cumcnt': 'int16',\n","        'lectures_cumcnt_part': 'int16',\n","        'lectures_cumcnt_tag_0': 'int16',\n","        'lectures_cumcnt_tags': 'int16',\n","        'lectures_cumcnt_session': 'int16',\n","        'task_container_id_orig': 'int16',\n","        'ts_minute': 'int16',\n","        'session_minute_max': 'int16',\n","        'pqet_sec': 'int16',\n","        'pqet_sec_rollavg': 'int16',\n","        'session': 'uint8',\n","        'r_cumcnt_clip': 'int16'\n","    }\n","}\n","\n","dtypes_content_tags = {\n","    'ql_id': 'int16',\n","    'question_id': 'int16',\n","    'lecture_id': 'int16',\n","    'bundle_id': 'uint16',\n","    'correct_answer': 'uint8',\n","    'part': 'int8',\n","    'tags': 'str',\n","    'tags_array': 'str',\n","    'tag_0': 'uint8',\n","    'part_correct_pct': 'int8',\n","    'tag_0_correct_pct': 'int8',\n","    'question_id_correct_pct': 'int8',\n","    'tags_correct_pct': 'int8',\n","    'tags_code': 'int16'\n","}\n","\n","# each of these gets cumsums for correct and\n","# incorrect, row count and pct correct\n","cumsum_cols = {\n","    'ac_cumsum': 'int16',\n","    'ac_cumsum_content_id': 'int16',\n","    'ac_cumsum_part': 'int16',\n","    'ac_cumsum_session': 'int16',\n","    'ac_cumsum_tag_0': 'int16',\n","    'ac_cumsum_tags': 'int16',\n","    'ac_cumsum_upto': 'int8',\n","}\n","\n","for c, t in cumsum_cols.items():\n","    dtypes_new['train'][c] = t\n","    r_col = c.replace('ac_cumsum', 'r_cumcnt')\n","    dtypes_new['train'][r_col] = t\n","    i_col = c.replace('ac_cumsum', 'aic_cumsum')\n","    dtypes_new['train'][i_col] = t\n","    p_col = c.replace('ac_cumsum', 'ac_cumsum_pct')\n","    dtypes_new['train'][p_col] = 'int8'\n","\n","dtypes = {}\n","for table_id in dtypes_orig:\n","    dtypes[table_id] = {\n","        **dtypes_orig[table_id],\n","        **dtypes_new[table_id]\n","    }\n","\n","dtypes = {\n","    **dtypes['train'],\n","    **dtypes_content_tags\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QhPzQmvUjuQV"},"source":["### BigQuery Table Schemas"]},{"cell_type":"code","metadata":{"trusted":true,"id":"WdW0igS4juQW"},"source":["# <hide-input>\n","type_map = {\n","    'int64': 'INTEGER',\n","    'int32': 'INTEGER',\n","    'int16': 'INTEGER',\n","    'int8': 'INTEGER',\n","    'uint8': 'INTEGER',\n","    'uint16': 'INTEGER',\n","    'str': 'STRING',\n","    'bool': 'BOOL',\n","    'float32': 'FLOAT'\n","}\n","\n","schemas_orig = {table: [SchemaField(f, type_map[t]) for f, t in\n","                   fields.items()] for table, fields in dtypes_orig.items()}\n","\n","schemas = {}\n","for table_id, fields in dtypes_new.items():\n","    new_fields = [SchemaField(f, type_map[t]) for\n","                  f, t in fields.items()]\n","    schemas[table_id] = schemas_orig[table_id] + new_fields"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GOpOrtr9juQY"},"source":["### Load Tables"]},{"cell_type":"code","metadata":{"trusted":true,"id":"saboKI_rjuQc"},"source":["# <hide-input>\n","# Load questions from local json file - can't load tags as array from csv.\n","\n","# only reason to use this is if using one-hot tags\n","if False:\n","    bqh.del_table('questions')\n","    \n","    df_questions = pd.read_csv(f'gs://{BUCKET}/questions.csv')\n","    df_questions.tags = df_questions.tags.fillna('189')\n","    df_questions.tags = df_questions.tags.str.split()\n","    \n","    if one_hot_tags:\n","        mlb = MultiLabelBinarizer()\n","        one_hots = (mlb.fit_transform(df_questions.tags\n","                    .apply(lambda l: [f'tag_{int(t):03d}' for t in l])))\n","        df_one_hots = pd.DataFrame(one_hots, columns = mlb.classes_)\n","        df_questions = pd.concat([df_questions, df_one_hots], axis=1)\n","    \n","    df_questions.to_json('questions.json', orient=\"records\", lines=True)\n","    lj = bqh.load_json_file('questions', schemas).result()\n","\n","# tags to array logic moved to sql, ok to load csv directly\n","# doesn't create one-hot tags\n","if False:\n","    bqh.del_table('questions')\n","    lj = bqh.load_csv_uri('questions', schemas_orig).result()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"XXwb4YkWjuQe"},"source":["# <hide-input>\n","if False:\n","    for table_id in dtypes_orig:\n","        bqh.del_table(table_id)\n","        lj = bqh.load_csv_uri(table_id, schemas_orig).result()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"CHkK8JhQjuQg"},"source":["# <hide-input><hide-output>\n","df_jobs = bqh.get_df_jobs()\n","df_jobs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rdk5EpmsQ7Pl"},"source":["if False:\n","    job = bq_client.get_job(df_jobs.iloc[1].job_id)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"5cGVHAtMjuQi"},"source":["# <hide-input>\n","df_table_list = bqh.get_df_table_list()\n","df_table_list"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sgTZkanIjuQk"},"source":["### Update Table Schemas"]},{"cell_type":"code","metadata":{"trusted":true,"id":"_t7T4NftjuQk"},"source":["# <hide-input>\n","if False:\n","    for table_id, schema in schemas.items():\n","        table = bqh.get_table(table_id)\n","        table.schema = schema\n","        table = bq_client.update_table(table, ['schema'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ouoo1oQCjuQm"},"source":["## Engineer Features"]},{"cell_type":"markdown","metadata":{"id":"CU8m9kx9juQn"},"source":["A good workflow here is:\n","* Create a sample of the train table.\n","* Use the BigQuery query editor user interface to get the SQL for a new feature worked out as a selection from the `train_sample` table. The user interface there has tab completion, syntax checking and displays results, which makes creating and debugging queries a snap.\n","    * [BigQuery Console](https://console.cloud.google.com/bigquery?project=riiid-caleb) (Update project query string for your project.)\n","    * [BigQuery Query syntax in Standard SQL](https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax) is your friend.\n","* Optional: create a local dataframe, using the export functions below, to confirm that it is working the right way.\n","* Add a column to the appropriate table by adding a value to `dtypes_new`\n","* Update the schema for the table in BigQuery by running the Update Table Schemas cell above\n","* Recreate the `train_sample` table by running the cell below.\n","* Use the BigQuery query editor user interface add the logic to update the new column.\n","* Optional: create a local dataframe, using the export functions below, to confirm that the update is working the right way.\n","* Copy the SQL to a new method in the `Queries` class above\n","* Add the query to the appropriate `run_transformations` function above\n","* Run transformations on `train_sample` table\n","* Inspect `train_sample` table in BigQuery to confirm everything is working correctly\n","* Optional: load load local dataframe using `get_df_query` function for further inspection\n","* Run transformations on `train` table\n","* Inspect `train` table in BigQuery to confirm everything is working correctly\n","* Optional: load local dataframe using `get_df_query` function for further inspection"]},{"cell_type":"markdown","metadata":{"id":"CfKY_WsvjuQp"},"source":["### Perform Transformations"]},{"cell_type":"markdown","metadata":{"id":"ZOnBP6sfjuQp"},"source":["#### Train Table\n","* Update task_container_id to increase monotonically with timestamp\n","    * There were some `task_conatiner_id`s that were out of order with respect to timestamp. They needed to be be ordered correctly so that cumulative and rolling sums partitioned by `task_container_id` would be include only interactions with earlier `timestamps`. Even though all interactions with the same `task_container_id` have the same `timestamp`, partioning by `timestamp` is much slower (because the range of values is so much wider?).\n","* Calc answered_incorrectly\n","    * `answered_correctly` for lectures was recorded as -1 and needed to be set to 0 to calculate cumulative and rolling sums correctly including lectures. As a consequence, `answered_incorrectly` could be calculated as the inverse of `answered_correctly`.\n","* Calc cumsum for `answered_correctly` and `answered_incorrectly` by `user_id` and by `user_id` and `content_id` and rolling avg for `prior_question_elapsed_time` by user \n","    * This is done so that the totals are as of the preceding `task_container_id`\n","* Calculate rolling sum for `answered_correctly` and `answered_incorrectly` by `user_id`\n","    * Includes the 10 rows preceding the current `task_container_id`\n","    * I couldn't figure out how to get this done with the standard window functionality since I wanted a set number of rows preceding the current task container (as opposed to just the current row), so it joins on `user_id` with a `task_container_id` less than the current one, which takes a while to complete.\n","* Calculate answered correctly percentages for `answered_correctly_cumsum`, `answered_correctly_rollsum` and `answered_correctly_content_id_cumsum_pct`"]},{"cell_type":"code","metadata":{"id":"p56xi-SBW8-N"},"source":["if False:\n","    q = Q.update_train_window_containers_time(table_id='train')\n","    qj = bqh.run_query(*q, wait=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"r2LZdBETjuQs"},"source":["# <hide-input>\n","def run_train_transforms(table_id=None):\n","    # Run serially to avoid update conflicts\n","    \n","    train_queries = [\n","        Q.update_ql_id(table_id=table_id),\n","        Q.update_task_container_id(table_id=table_id),\n","        Q.update_missing_values(table_id=table_id,\n","                                column_id='prior_question_had_explanation',\n","                                value='false'),\n","        Q.update_missing_values(table_id=table_id,\n","                                column_id='prior_question_elapsed_time',\n","                                value='0'),\n","        Q.update_answered_correctly(table_id=table_id),\n","        Q.update_train_window_containers_pqet(table_id=table_id),\n","        Q.update_train_window_containers_session(table_id=table_id, session_hours=72),\n","        Q.update_train_window_containers(table_id=table_id),\n","        Q.update_train_window_containers_tag_0(table_id=table_id),\n","        Q.update_train_window_containers_tags(table_id=table_id),\n","        Q.update_answered_correctly_cumsum_upto(table_id=table_id)\n","    ]\n","\n","    train_queries_not_run = [\n","        Q.update_train_window_rows(table_id=table_id, window=10)\n","    ]\n","    \n","    _ = [bqh.run_query(*q, wait=True) for q in train_queries]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2JEU6G0hMLkP"},"source":["#### Questions Table\n","* Calculate percent answered correctly for `question_id`, `part` and `tag__0`\n","* Add question columns\n","    * Adding question part and the first associated tag. (There wasn't any official information regarding the order of the tags as recorded for each question, but they did not appear to be sorted so it seems possible the order in which they are recorded is significant.)"]},{"cell_type":"code","metadata":{"id":"jG596OjGtm5Y"},"source":["# <hide-input>\n","def run_questions_transforms_before():\n","    \"\"\"These have to be run BEFORE the transforms are run on the full\n","    train table.\n","    \"\"\"\n","    \n","    questions_queries = [Q.update_missing_values('questions', 'tags', '\"189\"'),\n","                         Q.create_table_content_tags()]\n","    \n","    _ = [bqh.run_query(*q, wait=True).result() for q in questions_queries]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"8Ay24JcgjuQv"},"source":["# <hide-input>\n","def run_questions_transforms_after():\n","    \"\"\"These have to be run AFTER the transforms are run on the full\n","    train table.\n","    \"\"\"\n","    questions_queries = []\n","    for column_id in ['question_id', 'part', 'tag_0', 'tags']:\n","        questions_queries.append(Q.update_content_tags_correct_pct(column_id))\n","    \n","    _ = [bqh.run_query(*q, wait=True).result() for q in questions_queries]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"tuh_k3VfjuQx"},"source":["# <hide-input>\n","if False:\n","    run_questions_transforms_before()\n","    # run_train_transforms('train')\n","    run_questions_transforms_after()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YTG_h2a2juQy"},"source":["### Check Output"]},{"cell_type":"code","metadata":{"trusted":true,"id":"12-1u5TdjuQ1"},"source":["query = Q.select_train(table_id='train', excl_lectures=True)\n","df_query = bqh.get_df_query(query, dtypes=dtypes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"ub-U0nPgjuQ3"},"source":["# <hide-input>\n","cols = [\n","        'row_id',\n","        'task_container_id_orig',\n","        'timestamp',\n","        'content_type_id',\n","        'user_id',\n","        'task_container_id',\n","        'part',\n","        'tag__0',\n","        'answered_correctly',\n","        'answered_incorrectly',\n","        'answered_correctly_cumsum',\n","        'answered_incorrectly_cumsum',\n","        'answered_correctly_content_id_cumsum',\n","        'answered_correctly_rollsum',\n","        'answered_incorrectly_rollsum',\n","        'answered_incorrectly_content_id_cumsum',\n","        'part_correct_pct',\n","        'tag__0_correct_pct',\n","        'question_id_correct_pct',\n","        'prior_question_elapsed_time',\n","        'prior_question_elapsed_time_rollavg',\n","        'prior_question_had_explanation',\n","        'lectures_cumcount',\n","        'answered_correctly_cumsum_upto'\n","]\n","\n","df_user = df_query[cols].copy()\n","df_user.timestamp = df_user.timestamp / (1000*60*60)\n","\n","df_user.loc[df_user.user_id == 44331].head(20)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zO6GM_CLjuQ5"},"source":["### Visually Inspect Features"]},{"cell_type":"markdown","metadata":{"id":"jpokxssbjuQ6"},"source":["The charts below can also be used to visually inspect whether the transformations have been performed correctly."]},{"cell_type":"code","metadata":{"trusted":true,"id":"0c-xlk2TjuQ6"},"source":["# <hide-input>\n","groups = {\n","    'cum': {\n","        'columns': {\n","            'task_container_id': 0,\n","            'answered_correctly_cumsum': 2,\n","            'answered_incorrectly_cumsum': 1\n","        },\n","        'xaxis': 'elapsed_hours'\n","    },\n","    'roll': {\n","        'columns': {\n","            'answered_correctly_rollsum': 2,\n","            'answered_correctly': 7,\n","            'answered_incorrectly_rollsum': 1,\n","            'answered_incorrectly': 8,\n","            'part': 9\n","        },\n","        'xaxis': 'row_id'\n","    },  \n","    'correct_pct': {\n","        'columns': {\n","            'question_id_correct_pct': 0,\n","            'part_correct_pct': 5,\n","            'tag__0_correct_pct': 6\n","        },\n","        'xaxis': 'row_id'\n","    },  \n","    'prior_question_elapsed_time': {\n","        'columns': {\n","            'prior_question_elapsed_time': 0,\n","        },\n","        'xaxis': 'row_id'\n","    },  \n","    'prior_question_had_explanation': {\n","        'columns': {\n","            'prior_question_had_explanation': 0,\n","        },\n","        'xaxis': 'row_id'\n","    }\n","}\n","\n","def plot_user_learning(user_id=None, group=None, suffix=None):\n","    theme = px.colors.qualitative.Plotly\n","    columns = list(group['columns'].keys())\n","    colors = [theme[c] for c in group['columns'].values()]\n","\n","    df_query['elapsed_hours'] = df_query.timestamp / (1000*60*60)\n","\n","    df = (df_query.loc[(df_user.user_id == user_id) &\n","                       (df_user.content_type_id == 0)])\n","\n","    # labels = {'value': 'answer count'}\n","\n","    fig = df.plot(x=group['xaxis'], y=columns, color_discrete_sequence=colors,\n","                  title=f'Learning Progress - user_id = {user_id} - {suffix}')\n","    fig.data\n","\n","    return fig\n","\n","user_id_random = np.random.choice(df_query.user_id.unique(), (1,))[0]\n","use_random = False\n","user_id =  user_id_random if use_random else 5382\n","\n","for k, v in groups.items():\n","    fig = plot_user_learning(user_id, v, k)\n","    fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Axb2oD77juRM"},"source":["### Create Folds"]},{"cell_type":"markdown","metadata":{"id":"jNsk1_JsjuRN"},"source":["The objectives for the validation split are as follows:\n","* Include some users that don't exist in the training set\n","* Include records for some users in the validation set with timestamps greater than all of those users' records in the training set\n","\n","This is achieved by first setting the percentage of users that will only occur in the training set and then setting the percentage of the remaining users that will have records in both.\n","\n","The split between the validation and training sets for the users with records in both is determined by randomly selecting a number between zero and the maximum task_container_id for each user and including in the validation set all records with a task_container_id greater than that for each user."]},{"cell_type":"code","metadata":{"id":"A_nmEi_1gMFf"},"source":["# <hide-input>\n","# create validation split table\n","# this needs to run after the task container Ids have been updated\n","\n","table_id_folds = 'folds'\n","if True:\n","    qj = bqh.run_query(*Q.create_table_folds(table_id=table_id_folds), wait=True)\n","    qj = bqh.run_query(*Q.update_folds(table_id_folds=table_id_folds), wait=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PX-J3AaG5FxM"},"source":["# <hide-input>\n","# TODO: bring in diagnostic charts from folding is fun\n","if False:\n","    df_folds = bqh.get_df_table('folds', None)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7GBDKOZ2juRA"},"source":["With feature engineering being performed in BigQuery, data has to be exported to train models locally. The [Python Client for Google BigQuery](https://googleapis.dev/python/bigquery/latest/index.html) [to_dataframe()](https://googleapis.dev/python/bigquery/latest/generated/google.cloud.bigquery.job.QueryJob.html?highlight=to_dataframe#google.cloud.bigquery.job.QueryJob.to_dataframe) makes it possible to create dataframes directly, but is prohibitively slow for large datasets. While it is not possible to export table directly to the local file system, it is possible to export to cloud storage and then download locally from there. This is reasonably efficient, taking a couple of minutes to run a query, export to cloud storage, download to the local file system and then read the files into a dataframe. The is another api, the [BigQuery Storage API](https://cloud.google.com/bigquery/docs/reference/storage), that a client can be created with that is really fast and works with the `to_dataframe` method, but unforunatley it isn't working with the current Kaggle kernel environment.\n","\n","The functions below take advantage of the fact BigQuery stores queries in temporary tables so that preveiously requested queries can be retrieved without having to run them again. Similarly, the functions below name the exported files with the reference to the BigQuery temporary table, so that if a function is run to create a dataframe from a query for which the files already exist in cloud storage or locally, they won't be exported or downloaded again. "]},{"cell_type":"markdown","metadata":{"id":"F_B3C-9QjuQ9"},"source":["### Create Sample of Train Table for R&D"]},{"cell_type":"code","metadata":{"trusted":true,"id":"tuNFCT1OjuQ9"},"source":["# <hide-input>\n","if False:\n","    ts_id = 'train_sample'\n","    bqh.del_table(ts_id)\n","    bqh.run_query(*Q.create_train_sample(ts_id), wait=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wbaxOZFVjuRA"},"source":["## Create Local Dataframe"]},{"cell_type":"markdown","metadata":{"id":"oMqolxVmjuRL"},"source":["## Train Model"]},{"cell_type":"markdown","metadata":{"id":"xV-qHbTc2oly"},"source":["### Select Features to Export"]},{"cell_type":"code","metadata":{"id":"rnDz1XqY5g-n"},"source":["# <hide-input><hide-output>\n","if False:\n","    feats = sorted([f\"\"\"'{k+\"':\":<32} {v},\"\"\" for k,v in features.items()])\n","    for f in feats:\n","        print(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"QUkacRjajuRG"},"source":["# <hide-input>\n","features = {\n","    'ac_cumsum':                      [True, True],\n","    'ac_cumsum_content_id':           [True, True],\n","    'ac_cumsum_part':                 [True, True],\n","    'ac_cumsum_pct':                  [True, True],\n","    'ac_cumsum_pct_content_id':       [True, True],\n","    'ac_cumsum_pct_part':             [True, True],\n","    'ac_cumsum_pct_session':          [True, True],\n","    'ac_cumsum_pct_tag_0':            [True, True],\n","    'ac_cumsum_pct_tags':             [True, True],\n","    'ac_cumsum_pct_upto':             [True, True],\n","    'ac_cumsum_session':              [True, True],\n","    'ac_cumsum_tag_0':                [True, True],\n","    'ac_cumsum_tags':                 [True, True],\n","    'ac_cumsum_upto':                 [True, True],\n","    'aic_cumsum':                     [True, True],\n","    'aic_cumsum_content_id':          [True, True],\n","    'aic_cumsum_part':                [True, True],\n","    'aic_cumsum_session':             [True, True],\n","    'aic_cumsum_tag_0':               [True, True],\n","    'aic_cumsum_tags':                [True, True],\n","    'aic_cumsum_upto':                [True, True],\n","    'bundle_id':                      [False, False],\n","    'answered_correctly':             [True, False],\n","    'content_id':                     [True, False],\n","    'content_type_id':                [True, False],\n","    'correct_answer':                 [True, True],\n","    'fold':                           [True, False],\n","    'lecture_id':                     [False, False],\n","    'lectures_cumcnt':                [True, True],\n","    'lectures_cumcnt_part':           [True, True],\n","    'lectures_cumcnt_session':        [True, True],\n","    'lectures_cumcnt_tag_0':          [True, True],\n","    'lectures_cumcnt_tags':           [True, True],\n","    'part':                           [True, True],\n","    'part_correct_pct':               [True, True],\n","    'pqet_sec':                       [True, True],\n","    'pqet_sec_rollavg':               [True, False],\n","    'prior_question_elapsed_time':    [True, True],\n","    'prior_question_had_explanation': [True, True],\n","    'ql_id':                          [False, False],\n","    'question_id':                    [False, False],\n","    'question_id_correct_pct':        [True, True],\n","    'r_cumcnt':                       [True, True],\n","    'r_cumcnt_clip':                  [True, True],\n","    'r_cumcnt_content_id':            [True, True],\n","    'r_cumcnt_part':                  [True, True],\n","    'r_cumcnt_session':               [True, True],\n","    'r_cumcnt_tag_0':                 [True, True],\n","    'r_cumcnt_tags':                  [True, True],\n","    'r_cumcnt_upto':                  [True, True],\n","    'row_id':                         [True, False],\n","    'session':                        [True, True],\n","    'session_minute_max':             [True, False],\n","    'tag_0':                          [True, True],\n","    'tag_0_correct_pct':              [True, True],\n","    'tags':                           [True, False],\n","    'tags_array':                     [False, False],\n","    'tags_code':                      [True, True],\n","    'tags_correct_pct':               [True, True],\n","    'task_container_id':              [True, False],\n","    'task_container_id_orig':         [False, False],\n","    'timestamp':                      [True, True],\n","    'ts_minute':                      [True, True],\n","    'user_answer':                    [True, False],\n","    'user_id':                        [True, False]\n"," }\n","\n","columns_export = [f for f, v in features.items() if v[0]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"32Wt1DvjpnJZ"},"source":["# <hide-input>\n","def get_features_widget(features_dict, columns_list, idx):\n","\n","    names = []\n","    widget_list = []\n","    for key, v in features_dict.items():\n","        widget_list.append(widgets.ToggleButton(value=v[idx],\n","                                                description=key,\n","                                                layout={'width': '290px'},\n","                                                button_style='primary'))\n","        names.append(key)\n","\n","    arg_dict = {names[i]: widget for i, widget in enumerate(widget_list)}\n","\n","    layout = widgets.Layout(grid_template_columns=\"repeat(3, 300px)\")\n","    ui = widgets.GridBox(widget_list, layout=layout)\n","\n","    def select_data(**kwargs):\n","        columns_list.clear()\n","\n","        for key in kwargs:\n","            features_dict[key][idx] = False\n","            if kwargs[key]:\n","                columns_list.append(key)\n","                features_dict[key][idx] = True\n","\n","        print(f'{len(columns_list)} columns selected')\n","\n","    output = widgets.interactive_output(select_data, arg_dict)\n","    return ui, output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B6ddqQ4HBT3R"},"source":["# <hide-input>\n","display(*get_features_widget(features, columns_export, 0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"EXRXQ86UjuRK"},"source":["%%time\n","# <hide-output>\n","if False:\n","    folds = list(range(10))\n","    \n","    query = Q.select_train(columns=columns_export, folds=folds,\n","                           excl_lectures=True, limit=None)\n","    \n","    df_train = bqh.get_df_query_gcs(query, dtypes=dtypes, file_format='csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TAIxa0UkIZCF"},"source":["if False:\n","    \n","    base_cols = [\n","            'user_id',\n","            'task_container_id',\n","            'row_id',\n","            'content_id',\n","            'content_type_id',\n","            'prior_question_had_explanation',\n","            'answered_correctly',\n","    ]\n","    \n","    col = 'session'\n","    \n","    cum_cols = [\n","            'ac_cumsum',\n","            'aic_cumsum',\n","            'r_cumcnt',\n","            'r_cumcnt_clip',\n","            'ac_cumsum_pct',\n","            'lectures_cumcnt',\n","            f'ac_cumsum_{col}',\n","            f'aic_cumsum_{col}',\n","            f'r_cumcnt_{col}',\n","            f'ac_cumsum_pct_{col}',\n","            f'lectures_cumcnt_{col}'\n","    ]\n","\n","    q_cols = [\n","              'part',\n","              'tags',\n","              'tag_0',\n","              'question_id_correct_pct',\n","              'part_correct_pct',\n","              'tag_0_correct_pct',\n","              'tags_correct_pct'\n","    ]\n","\n","    time_cols = [\n","            'prior_question_elapsed_time',\n","            'timestamp',\n","            'ts_minute',\n","            'session_minute_max',\n","            'pqet_sec',\n","            'pqet_sec_rollavg',\n","            'session'\n","    ]\n","\n","# df_test = bqh.get_df_query_gcs(('SELECT * FROM data.train t JOIN data.content_tags c ON t.ql_id = c.ql_id WHERE user_id IN (1827855198, 1066383521) ORDER BY user_id, task_container_id, row_id', '_test'), dtypes=None, file_format='json')\n","\n","# df_test[base_cols + cum_cols][df_test.user_id == 1827855198].tail(60)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8VM6n9FKyczN"},"source":["### Select Columns for Training"]},{"cell_type":"code","metadata":{"id":"MUSDoZoLEKP_"},"source":["# <hide-input>\n","columns_train = []\n","display(*get_features_widget(features, columns_train, 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q-zrGOfDwjw9"},"source":["# <hide-input>\n","def show_features():\n","    df_features = pd.DataFrame(features).T.reset_index()\n","    df_features.columns = ['feature', 'export', 'train']\n","    df_features\n","\n","    def highlight_true(s):\n","        return ['background-color: lightskyblue' if v else '' for v in s]\n","    return df_features.style.apply(highlight_true, subset=['export', 'train'])\n","show_features()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a05rC3CdDYg0"},"source":["folds_dict = {}\n","if True:\n","    folds = list(range(30))\n","    \n","    for fold in folds:\n","        query = Q.select_train(columns=['answered_correctly'] + columns_train, folds=[fold],\n","                            excl_lectures=True, limit=None)\n","        \n","        prefix = bqh.export_query_gcs(query, header=False)\n","        file_paths = bqh.get_table_gcs(prefix)\n","        folds_dict[fold] = dict(prefix=prefix,file_paths=file_paths)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nluvlo-SGun9"},"source":["def get_dmatrices_csv(folds_train=None, folds_val=None):\n","    \n","    def combine_folds(folds, cache_fp=None):\n","        if cache_fp is not None and Path(cache_fp).exists():\n","            Path(cache_fp).unlink()\n","            Path(f'{cache_fp}.row.page').unlink()\n","            \n","        fp_combined = Path('combined.csv')\n","        if fp_combined.exists():\n","            fp_combined.unlink()\n","        \n","        with open(fp_combined,\"wb\") as fout:\n","            for fold in tqdm(folds):\n","                for fp in folds_dict[fold]['file_paths']:\n","                    with open(fp, \"rb\") as fin:\n","                        fout.write(fin.read())\n","\n","        uri = f'{fp_combined.name}?format=csv&label_column=0'\n","\n","        if cache_fp is not None:\n","            uri += f'#{cache_fp}'\n","        \n","        return xgb.DMatrix(uri, feature_names=columns_train)\n","        \n","    return {'train_matrix': combine_folds(folds_train, 'train.cache'),\n","            'valid_matrix': combine_folds(folds_val, 'valid.cache'),\n","            'folds_train': folds_train,\n","            'folds_val': folds_val\n","            }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aBkXUoMmtPO1"},"source":["for f in folds_dict:"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"reut9PmcjuRV"},"source":["# <hide-input>\n","def get_dmatrices(folds_train=None, folds_val=None, matrix=xgb.DMatrix):\n","    y_train_col = ['answered_correctly']\n","\n","    x_train_cols = columns_train\n","\n","    mask_train = df_train.fold.isin(folds_train)\n","    mask_valid = df_train.fold.isin(folds_val)\n","\n","    train_matrix = matrix(data=df_train.loc[mask_train][x_train_cols],\n","                            label=df_train.loc[mask_train][y_train_col])\n","\n","    valid_matrix = matrix(data=df_train.loc[mask_valid][x_train_cols],\n","                            label=df_train.loc[mask_valid][y_train_col])\n","    \n","    return {'train_matrix': train_matrix,\n","            'valid_matrix': valid_matrix,\n","            'folds_train': folds_train,\n","            'folds_val': folds_val\n","            }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E5gUTzNtjuRX"},"source":["### Train Model"]},{"cell_type":"code","metadata":{"trusted":true,"id":"t6AeR8lBjuRX"},"source":["# <hide-output>\n","params = {\n","    'eta': 0.1,\n","    # 'max_depth': 10,\n","    # 'max_bin': 512,\n","    'tree_method': 'gpu_hist',\n","    'grow_policy': 'lossguide',\n","    'sampling_method': 'gradient_based',\n","    'objective': 'binary:logistic',\n","    'eval_metric': ['logloss', 'error', 'auc'],\n","    'subsample': 0.1\n","}\n","\n","def train_model(params=params, train_matrix=None, valid_matrix=None,\n","                folds_train=None, folds_val=None, verbose_eval=True, comet_summary=1):\n","    if NOT_KAGGLE:\n","        experiment = Experiment(display_summary_level=comet_summary)\n","        # experiment.set_name('with gap_minute_avg')\n","        experiment.log_parameter('folds_train', folds_train)\n","        experiment.log_parameter('folds_val', folds_val)\n","        # experiment.log_parameter('df_train_len', len(df_train))\n","\n","    evals_result = {}\n","    model = xgb.train(params=params, dtrain=train_matrix, num_boost_round=1000,\n","                    evals=[(train_matrix, 'train'), (valid_matrix, 'valid')],\n","                    evals_result=evals_result, early_stopping_rounds=20,\n","                    verbose_eval=verbose_eval)\n","\n","    if NOT_KAGGLE:\n","        exp_key = experiment.get_key()\n","        model.save_model(f'{exp_key}.xgb')\n","        experiment.log_model(exp_key, f'{exp_key}.xgb')\n","        experiment.end()\n","        \n","    return model, exp_key\n","    \n","exps = {}\n","\n","folds_list = [\n","    {'folds_train': folds[0:-2], 'folds_val': folds[-2:]}\n","]\n","\n","for folds_run in folds_list:\n","    model, exp_key = train_model(params, **get_dmatrices_csv(**folds_run),\n","                                 verbose_eval=False, comet_summary=1)\n","    exps[exp_key] = model.attributes()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fe7JKQf0juRZ"},"source":["## Evaluate Model"]},{"cell_type":"code","metadata":{"trusted":true,"id":"qPTKUFJMjuRZ"},"source":["# <hide-input>\n","def get_evals_df(evals_result):\n","    evals_list = []\n","    for k,v in evals_result.items():\n","        for j,u in v.items():\n","            evals_list.extend([{'epoch': i,\n","                                'split': k,\n","                                'metric': j,\n","                                'result': r} for i,r in enumerate(u)])\n","    \n","    df_evals = (pd.DataFrame(evals_list).set_index(['split', 'metric', 'epoch'])\n","                .unstack('metric'))\n","    df_evals.columns = df_evals.columns.get_level_values(1)\n","    df_evals.columns.name = None\n","    \n","    return df_evals.reset_index()\n","\n","df_evals = get_evals_df(evals_result)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"oa7h74fSjuRb"},"source":["# <hide-input>\n","df_evals.plot(x='epoch', y=['auc', 'logloss'],\n","              facet_col='split', title='Learning Curves')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"iIK9aXVpjuRd"},"source":["# <hide-input>\n","imps = model.get_score(importance_type='gain').items()\n","df_imp = pd.DataFrame(imps, columns=['feature', 'importance'])\n","df_imp = df_imp.set_index('feature').sort_values('importance', ascending=False)\n","df_imp.plot(kind='bar', y='importance', title='Feature Importances - Gain')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MwBUgoWhI6hu"},"source":["## Light GBM"]},{"cell_type":"code","metadata":{"id":"i5eKbbg7vkpy"},"source":["git.status()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qbLXXiPkQAt6"},"source":["cat_cols = ['correct_answer', 'part', 'tag_0']\n","\n","lgbm_params = {\n","    'objective': 'binary',\n","    'metric': ['binary_logloss', 'binary_error', 'auc'],\n","    'device': 'gpu'\n","}\n","\n","folds_run = {'folds_train': folds[0:9], 'folds_val': folds[9:]}\n","\n","matrices = get_dmatrices(folds_train=folds_run['folds_train'],\n","                         folds_val=folds_run['folds_val'],\n","                         matrix=lgb.Dataset)\n","\n","\n","experiment = Experiment(display_summary_level=1)\n","experiment.log_parameter('folds_train', matrices['folds_train'])\n","experiment.log_parameter('folds_val', matrices['folds_val'])\n","experiment.log_parameter('df_train_len', len(df_train))\n","\n","evals_result = {}\n","model = lgb.train(\n","    params = lgbm_params,\n","    train_set = matrices['train_matrix'],\n","    valid_sets = matrices['valid_matrix'],\n","    num_boost_round = 1000,\n","    verbose_eval = 10,\n","    evals_result = evals_result,\n","    early_stopping_rounds = 10,\n","    categorical_feature = [columns_train.index(c) for c in cat_cols],\n","    feature_name = columns_train\n","    )\n","\n","experiment.end()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t49TzqNPq5pg"},"source":["## Prepare Prediction Data"]},{"cell_type":"markdown","metadata":{"id":"GXZ10jxVjuRf"},"source":["### Download Final Users State"]},{"cell_type":"code","metadata":{"trusted":true,"id":"3eJlJt1FjuRg"},"source":["# <hide-input><hide-output>\n","%%time\n","\n","if False:    \n","    query = Q.select_user_final_state(table_id='train', no_upto=10)\n","    df_users = bqh.get_df_query_gcs(query, dtypes=dtypes, file_format='csv')\n","    df_users.to_pickle('df_users.pkl')\n","    bucket.blob('df_users.pkl').upload_from_filename('df_users.pkl')\n","else:\n","    bucket.blob('df_users.pkl').download_to_filename('df_users.pkl')\n","    df_users = pd.read_pickle('df_users.pkl')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ccdPfyJ8WrhH"},"source":["df_users[df_users.user_id == 8623]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xok_9xlD7c0H"},"source":["### Download Final User-Content State"]},{"cell_type":"code","metadata":{"id":"RUVdoI5V8FD1"},"source":["# <hide-input><hide-output>\n","%%time\n","\n","if False:\n","    query = Q.select_user_content_final_state(table_id='train')\n","    df_users_content = bqh.get_df_query_gcs(query, dtypes=dtypes)\n","    df_users_content.to_pickle('df_users_content.pkl')\n","    bucket.blob('df_users_content.pkl').upload_from_filename('df_users_content.pkl')\n","else:\n","    bucket.blob('df_users_content.pkl').download_to_filename('df_users_content.pkl')\n","    df_users_content = pd.read_pickle(f'df_users_content.pkl')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IEdnHEoEbKNa"},"source":["df_users_content[(df_users_content.user_id == 8623) & (df_users_content.content_id == 763)]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EVS-PapIkfPG"},"source":["### Download Final User-Tags State"]},{"cell_type":"code","metadata":{"id":"-v6vBK7vkdzf"},"source":["# <hide-input><hide-output>\n","if False:\n","    query = Q.select_users_tag_final_state(table_id='train')\n","    df_users_tag = bqh.get_df_query_gcs(query, dtypes=dtypes, file_format='csv')\n","    df_users_tag.to_pickle('df_users_tag.pkl')\n","    bucket.blob('df_users_tag.pkl').upload_from_filename('df_users_tag.pkl')\n","else:\n","    bucket.blob('df_users_tag.pkl').download_to_filename('df_users_tag.pkl')\n","    df_users_tag = pd.read_pickle('df_users_tag.pkl')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m_RJCpSxcrGy"},"source":["df_users_tag[(df_users_tag.user_id == 8623) & (df_users_tag.tag == 69)]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tWvj0FYpjuRj"},"source":["### Download Content-Tags Table"]},{"cell_type":"code","metadata":{"trusted":true,"id":"mG3gRUwmjuRl"},"source":["# <hide-input><hide-output>\n","if False:\n","    # only 14k rows, so it downloaded directly from BigQuery\n","    df_content_tags = bqh.get_df_table('content_tags', max_results=None, dtypes=None)\n","    df_questions = df_content_tags[df_content_tags.lecture_id.isna()]\n","    del df_questions['lecture_id']\n","    df_questions = df_questions.astype({d: t for d, t in dtypes.items() if d in df_questions.columns})\n","    df_lectures = df_content_tags[df_content_tags.question_id.isna()][['ql_id', 'lecture_id', 'part', 'tags', 'tags_array', 'tag_0']]\n","    df_lectures = df_lectures.astype({d: t for d, t in dtypes.items() if d in df_lectures.columns})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_NH5WM3VjuRn"},"source":["## Update Kaggle Submission Dataset"]},{"cell_type":"code","metadata":{"id":"6GV4lXzRKvE8"},"source":["if False:\n","    exps={}\n","    e = 'ce9d161813854d3287b80a38b6968193'\n","    exp = APIExperiment(previous_experiment=e)\n","    exp.download_model(e)\n","    e_model = xgb.Booster(model_file=f'{e}.xgb')\n","    exps[e] = e_model.attributes()\n","\n","    columns_train = json.loads(exp.get_parameters_summary(\n","        parameter='feature_names')['valueCurrent'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"x0B8sbkGjuRo"},"source":["# <hide-input>\n","if False:\n","    Path(KAGGLE_SUBMIT_DATASET).mkdir(exist_ok=True)\n","\n","    with open(f'{KAGGLE_SUBMIT_DATASET}/columns.json', 'w') as cj:\n","            json.dump(columns_train, cj)\n","\n","    with open(f'{KAGGLE_SUBMIT_DATASET}/dtypes.json', 'w') as dj:\n","            json.dump(dtypes, dj)\n","    \n","    with open(f'{KAGGLE_SUBMIT_DATASET}/models.json', 'w') as mj:\n","        json.dump(exps, mj)\n","\n","    for m in exps:\n","        src = Path(f'{m}.xgb')\n","        (KAGGLE_SUBMIT_DATASET/src).write_bytes(src.read_bytes())\n","    \n","    df_files = {\n","        'df_users.pkl': df_users,\n","        'df_users_content.pkl': df_users_content,\n","        'df_users_tag.pkl': df_users_tag,\n","        'df_questions.pkl': df_questions,\n","        'df_lectures.pkl': df_lectures\n","    }\n","\n","    for file_path, df in df_files.items():\n","        if Path(file_path).exists():\n","            (Path(f'{KAGGLE_SUBMIT_DATASET}/{file_path}')\n","            .write_bytes(Path(file_path).read_bytes()))\n","        else:\n","            df.to_pickle(f'{KAGGLE_SUBMIT_DATASET}/{file_path}')\n","            \n","    kaggle_id = f\"{os.getenv('KAGGLE_USERNAME')}/{KAGGLE_SUBMIT_DATASET}\"\n","    \n","    metadata = {\n","        \"licenses\": [{\"name\": \"CC0-1.0\"}],\n","        \"id\": kaggle_id,\n","        \"title\": KAGGLE_SUBMIT_DATASET\n","    }\n","\n","    with open(f'{KAGGLE_SUBMIT_DATASET}/dataset-metadata.json', 'w') as f:\n","        json.dump(metadata, f)\n","            \n","    if kaggle_api.dataset_status(kaggle_id):\n","        kaggle_api.dataset_create_version(KAGGLE_SUBMIT_DATASET,\n","                                          version_notes='update dataset',\n","                                          delete_old_versions=True,\n","                                          dir_mode='tar',\n","                                          quiet=True\n","                                         )\n","    else:\n","        kaggle_api.dataset_create_new(KAGGLE_SUBMIT_DATASET,\n","                                      dir_mode='tar', quiet=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d-RK0etUwdw3"},"source":["## Push Kernel to Kaggle"]},{"cell_type":"code","metadata":{"id":"XoJcDapFwhCT"},"source":["# <hide-input>\n","if NOT_KAGGLE:\n","    if False:\n","        \n","        code_file = 'riiid-2020.ipynb'\n","        with open(DRIVE/REPO/code_file, 'r') as nb:\n","            nb_json = json.load(nb)       \n","        \n","        for i, cell in enumerate(nb_json['cells']):\n","            if cell['cell_type'] == 'code':\n","                \n","                # update show/hide code cells\n","                for h in ['input', 'output']:c\n","                    if cell['source'][0].find(f'<hide-{h}') > 1:\n","                        nb_json['cells'][i]['metadata'].update({f'_kg_hide-{h}': True})\n","                    else:\n","                        nb_json['cells'][i]['metadata'].pop(f'_kg_hide-{h}', None)\n","\n","                # add modules as cells\n","                if len(cell['source']) == 1:\n","                    groups = re.search(r'(?<=\\<include-)(.*?)(?=\\>)', cell['source'][0])\n","                    \n","                    if groups:\n","                        with open(DRIVE/REPO/groups.group(0), 'r') as m:\n","                            nb_json['cells'][i]['source'] = m.readlines() + nb_json['cells'][i]['source']    \n","\n","\n","        if Path(code_file).exists():\n","            Path(code_file).unlink()\n","        \n","        with open(f'{code_file}', 'w') as f:\n","            json.dump(nb_json, f)\n","\n","        data = {'id': 'calebeverett/riiid-bigquery-xgboost-end-to-end',\n","                        'title': 'RIIID: BigQuery-XGBoost End-to-End',\n","                        'code_file': code_file,\n","                        'language': 'python',\n","                        'kernel_type': 'notebook',\n","                        'is_private': 'false',\n","                        'enable_gpu': 'true',\n","                        'enable_internet': 'true',\n","                        'dataset_sources': [],\n","                        'competition_sources': ['riiid-test-answer-prediction'],\n","                        'kernel_sources': []}\n","        \n","        with open('kernel-metadata.json', 'w') as f:\n","            json.dump(data, f)\n","\n","        kaggle_api.kernels_push('.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HN5k3_N-juRp"},"source":["## Submit From Kernel"]},{"cell_type":"markdown","metadata":{"id":"BGXlGXmjjuRq"},"source":["* Go to [RIIID Submit](https://www.kaggle.com/calebeverett/riiid-submit), fork and update to reference your dataset."]},{"cell_type":"markdown","metadata":{"id":"vmHGcMTtEDZi"},"source":["## Push Submit Kernel to Kaggle"]},{"cell_type":"code","metadata":{"id":"h5oJG61mU9ES"},"source":["dataset_status = None\n","while dataset_status != 'ready':\n","    time.sleep(1)\n","    dataset_status = kaggle_api.datasets_status(CONFIG.get('KAGGLE_USERNAME'),\n","                                                KAGGLE_SUBMIT_DATASET)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iO6rPRH6EQJZ"},"source":["# <hide-input>\n","if NOT_KAGGLE:\n","    if True:\n","        submit_kernel = 'calebeverett/riiid-submit-private'\n","        kernel_path = Path('submit_kernel')\n","        kaggle_api.kernels_pull('calebeverett/riiid-submit-private', kernel_path, metadata=True)\n","        kaggle_api.kernels_push(kernel_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I4xRZVyHWFLT"},"source":["kaggle_api.kernels_status('calebeverett/riiid-submit-private')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_VVtvmvU3s9T"},"source":["## Update Experiments with Submission Results"]},{"cell_type":"code","metadata":{"id":"Qfp_-0ZMN7xT"},"source":["kaggle_api.kernels_list(mine=True, competition='riiid-test-answer-prediction')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ct8kmjFx30aw"},"source":["kaggle_api.competition_submissions_cli('riiid-test-answer-prediction')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wDpy6AmWx_U8"},"source":["if False:\n","    exp_keys = ['021c51e26e1e4a0795414429c0d0ea21', '1b2178bca8ae40ffb869adc2b948cfe3', '9351f247da8949eba061967c2642376e']\n","\n","    for exp_key in exp_keys:\n","        exp = APIExperiment(previous_experiment=exp_key)\n","        exp.log_other('submitted', True)\n","        exp.log_other('submitDate', '2020-11-19 06:39:18')\n","        exp.log_other('publicScore', 0.772)\n","        exp.log_other('kernelUrl', 'https://www.kaggle.com/calebeverett/riiid-submit-private?scriptVersionId=47216065')"],"execution_count":null,"outputs":[]}]}
=======
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "orpoYGXZdptj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"ip\": \"35.233.130.151\",\n",
      "  \"hostname\": \"151.130.233.35.bc.googleusercontent.com\",\n",
      "  \"city\": \"The Dalles\",\n",
      "  \"region\": \"Oregon\",\n",
      "  \"country\": \"US\",\n",
      "  \"loc\": \"45.5946,-121.1787\",\n",
      "  \"org\": \"AS15169 Google LLC\",\n",
      "  \"postal\": \"97058\",\n",
      "  \"timezone\": \"America/Los_Angeles\",\n",
      "  \"readme\": \"https://ipinfo.io/missingauth\"\n",
      "}"
     ]
    }
   ],
   "source": [
    "!curl ipinfo.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "N4lHWTOFrRgT",
    "toc-hr-collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <link href=\"//cdn.muicss.com/mui-0.10.3/css/mui.min.css\" rel=\"stylesheet\" type=\"text/css\" />\n",
       "    <div class=\"mui-container-fluid\">\n",
       "        <h2>Version History</h2>\n",
       "        <div style=\"max-width:1016px\" class=\"mui-row\">\n",
       "            <div class=\"mui-col-8\">\n",
       "                <table class=\"mui-table mui-table--bordered\">\n",
       "                    <tr>\n",
       "                        <th width=\"12%\" class=\"mui--align-bottom mui--bg-primary mui--text-light mui--text-center\">Version</th>\n",
       "                        <th width=\"12%\" class=\"mui--align-bottom mui--bg-primary mui--text-light mui--text-center\">Date</th>\n",
       "                        <th width=\"12%\" class=\"mui--align-bottom mui--bg-primary mui--text-light mui--text-center\">Local CV</th>\n",
       "                        <th width=\"12%\" class=\"mui--align-bottom mui--bg-primary mui--text-light mui--text-center\">Public<br>Leaderboard</th>\n",
       "                        <th class=\"mui--align-bottom mui--bg-primary mui--text-light mui--text-center mui--align-bottom mui--bg-primary\n",
       "                            mui--text-dark mui--text-left\">Notes</th>                    \n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td class=\"mui--align-top mui--text-center\">58</td>\n",
       "                        <td class=\"mui--align-top mui--text-center\">2020-11-15</td>\n",
       "                        <td class=\"mui--align-top mui--text-center\">0.756</td>\n",
       "                        <td class=\"mui--align-top mui--text-center\">0.762</td>\n",
       "                        <td><ul>\n",
       "                                <li>Completed submission pipeline with minimal feature set:\n",
       "                                    <ul>\n",
       "                                        <li><code>answered_correctly_content_id_cumsum</code></li>\n",
       "                                        <li><code>answered_correctly_cumsum</code></li>\n",
       "                                        <li><code>answered_correctly_cumsum_pct</code></li>\n",
       "                                        <li><code>answered_incorrectly_content_id_cumsum</code></li>\n",
       "                                        <li><code>answered_incorrectly_cumsum</code></li>\n",
       "                                        <li><code>part</code></li>\n",
       "                                        <li><code>part_correct_pct</code></li>\n",
       "                                        <li><code>question_id_correct_pct</code></li>\n",
       "                                        <li><code>tag__0</code></li>\n",
       "                                        <li><code>tag__0_correct_pct</code></li>\n",
       "                                        <li><code>task_container_id</code></li>\n",
       "                                        <li><code>timestamp</code></li>\n",
       "                                    </ul>\n",
       "                                </li>\n",
       "                                <li>Changed logic on roll sum to be over trailing\n",
       "                                    rows preceding the current <code>task_container_id</code> instead\n",
       "                                    of over trailing task containers\n",
       "                                    (expensive)\n",
       "                                </li>\n",
       "                            </ul>\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td class=\"mui--align-top mui--text-center\">53</td>\n",
       "                        <td class=\"mui--align-top mui--text-center\">2020-11-07</td>\n",
       "                        <td class=\"mui--align-top mui--text-center\">0.761</td>\n",
       "                        <td class=\"mui--align-top mui--text-center\">--</td>\n",
       "                        <td><ul><li>Housekeeping:\n",
       "                                    <ul>\n",
       "                                        <li>Consolidated notebook and modules in single repo</li>\n",
       "                                        <li>Streamlined Colab repo workflow using Drive</>\n",
       "                                        <li>Included modules in notebook when pushed to Kaggle</li>\n",
       "                                        <li>Eliminated CONFIG requirement when run in Kaggle</li>\n",
       "                                    </ul>\n",
       "                                </li>\n",
       "                            </ul>\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td class=\"mui--align-top mui--text-center\">40</td>\n",
       "                        <td class=\"mui--align-top mui--text-center\">2020-11-05</td>\n",
       "                        <td class=\"mui--align-top mui--text-center\">0.761</td>\n",
       "                        <td class=\"mui--align-top mui--text-center\">--</td>\n",
       "                        <td>\n",
       "                            <ul>\n",
       "                                <li>Features added:\n",
       "                                    <ul>\n",
       "                                        <li><code>answered_correctly_content_id_cumsum</code></li>\n",
       "                                        <li><code>answered_correctly_content_id_cumsum_pct</code></li>\n",
       "                                        <li><code>answered_correctly_cumsum10</code></li>\n",
       "                                        <li><code>answered_correctly_cumsum_pct</code></li>\n",
       "                                        <li><code>answered_correctly_rollsum_pct</code></li>\n",
       "                                        <li><code>answered_incorrectly_content_id_cumsum</code></li>\n",
       "                                        <li><code>lectures_cumcount</code></li>\n",
       "                                        <li><code>prior_question_elapsed_time_rollavg</code></li>\n",
       "                                    </ul>\n",
       "                                </li>\n",
       "                                <li>Single model, single fold</li>\n",
       "                                <li>No public leaderboard - efficient inference in progress</li>\n",
       "                                <li>Refactored code to move queries and helper functions into\n",
       "                                    separate modules</li>\n",
       "                                <li>Completed set up to commit code to Github from Colab and</li>\n",
       "                                <li>Completed set up to push kernels to Kaggle from Colab</li>\n",
       "                            </ul>\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td class=\"mui--align-top mui--text-center\">37</td>\n",
       "                        <td class=\"mui--align-top mui--text-center\">2020-11-04</td>\n",
       "                        <td class=\"mui--align-top mui--text-center\">0.751</td>\n",
       "                        <td class=\"mui--align-top mui--text-center\">0.748</td>\n",
       "                        <td>\n",
       "                            <ul>\n",
       "                                <li>Features added:\n",
       "                                    <ul>\n",
       "                                        <li><code>answered_correctly_cumsum</code></li>\n",
       "                                        <li><code>answered_correctly_rollsum</code></li>\n",
       "                                        <li><code>answered_incorrectly_cumsum</code></li>\n",
       "                                        <li><code>answered_incorrectly_rollsum</code></li>\n",
       "                                        <li><code>part</code></li>\n",
       "                                        <li><code>part_correct_pct</code></li>\n",
       "                                        <li><code>question_id_correct_pct</code></li>\n",
       "                                        <li><code>tag__0</code></li>\n",
       "                                        <li><code>tag__0_correct_pct</code></li>\n",
       "                                    </ul>\n",
       "                                </li>\n",
       "                                <li>Single model, single fold</li>\n",
       "                                <li>Model for public leaderboard didn't include\n",
       "                                    rolling features - still working out how to\n",
       "                                    efficiently calculate for inference</li>\n",
       "                            </ul>\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                </table>\n",
       "            </div>\n",
       "        </div>\n",
       "        <p>\n",
       "            <a href=\"https://colab.research.google.com/github/CalebEverett/riiid_2020/blob/master/riiid-2020.ipynb\" target=\"_blank\" rel=\"nofollow\">\n",
       "            <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
       "        </p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# <hide-input>\n",
    "def show_version_history():\n",
    "    from IPython.display import HTML\n",
    "    style_header = 'mui--align-bottom mui--bg-primary mui--text-light mui--text-center'\n",
    "    style_cell = 'mui--align-top mui--text-center'\n",
    "\n",
    "    # print(('\\n').join(list(map(make_li, sorted(dtypes.keys())))))\n",
    "\n",
    "    html_str = f\"\"\"\n",
    "    <link href=\"//cdn.muicss.com/mui-0.10.3/css/mui.min.css\" rel=\"stylesheet\" type=\"text/css\" />\n",
    "    <div class=\"mui-container-fluid\">\n",
    "        <h2>Version History</h2>\n",
    "        <div style=\"max-width:1016px\" class=\"mui-row\">\n",
    "            <div class=\"mui-col-8\">\n",
    "                <table class=\"mui-table mui-table--bordered\">\n",
    "                    <tr>\n",
    "                        <th width=\"12%\" class=\"{style_header}\">Version</th>\n",
    "                        <th width=\"12%\" class=\"{style_header}\">Date</th>\n",
    "                        <th width=\"12%\" class=\"{style_header}\">Local CV</th>\n",
    "                        <th width=\"12%\" class=\"{style_header}\">Public<br>Leaderboard</th>\n",
    "                        <th class=\"{style_header} mui--align-bottom mui--bg-primary\n",
    "                            mui--text-dark mui--text-left\">Notes</th>                    \n",
    "                    </tr>\n",
    "                    <tr>\n",
    "                        <td class=\"{style_cell}\">58</td>\n",
    "                        <td class=\"{style_cell}\">2020-11-15</td>\n",
    "                        <td class=\"{style_cell}\">0.756</td>\n",
    "                        <td class=\"{style_cell}\">0.762</td>\n",
    "                        <td><ul>\n",
    "                                <li>Completed submission pipeline with minimal feature set:\n",
    "                                    <ul>\n",
    "                                        <li><code>answered_correctly_content_id_cumsum</code></li>\n",
    "                                        <li><code>answered_correctly_cumsum</code></li>\n",
    "                                        <li><code>answered_correctly_cumsum_pct</code></li>\n",
    "                                        <li><code>answered_incorrectly_content_id_cumsum</code></li>\n",
    "                                        <li><code>answered_incorrectly_cumsum</code></li>\n",
    "                                        <li><code>part</code></li>\n",
    "                                        <li><code>part_correct_pct</code></li>\n",
    "                                        <li><code>question_id_correct_pct</code></li>\n",
    "                                        <li><code>tag__0</code></li>\n",
    "                                        <li><code>tag__0_correct_pct</code></li>\n",
    "                                        <li><code>task_container_id</code></li>\n",
    "                                        <li><code>timestamp</code></li>\n",
    "                                    </ul>\n",
    "                                </li>\n",
    "                                <li>Changed logic on roll sum to be over trailing\n",
    "                                    rows preceding the current <code>task_container_id</code> instead\n",
    "                                    of over trailing task containers\n",
    "                                    (expensive)\n",
    "                                </li>\n",
    "                            </ul>\n",
    "                        </td>\n",
    "                    </tr>\n",
    "                    <tr>\n",
    "                        <td class=\"{style_cell}\">53</td>\n",
    "                        <td class=\"{style_cell}\">2020-11-07</td>\n",
    "                        <td class=\"{style_cell}\">0.761</td>\n",
    "                        <td class=\"{style_cell}\">--</td>\n",
    "                        <td><ul><li>Housekeeping:\n",
    "                                    <ul>\n",
    "                                        <li>Consolidated notebook and modules in single repo</li>\n",
    "                                        <li>Streamlined Colab repo workflow using Drive</>\n",
    "                                        <li>Included modules in notebook when pushed to Kaggle</li>\n",
    "                                        <li>Eliminated CONFIG requirement when run in Kaggle</li>\n",
    "                                    </ul>\n",
    "                                </li>\n",
    "                            </ul>\n",
    "                        </td>\n",
    "                    </tr>\n",
    "                    <tr>\n",
    "                        <td class=\"{style_cell}\">40</td>\n",
    "                        <td class=\"{style_cell}\">2020-11-05</td>\n",
    "                        <td class=\"{style_cell}\">0.761</td>\n",
    "                        <td class=\"{style_cell}\">--</td>\n",
    "                        <td>\n",
    "                            <ul>\n",
    "                                <li>Features added:\n",
    "                                    <ul>\n",
    "                                        <li><code>answered_correctly_content_id_cumsum</code></li>\n",
    "                                        <li><code>answered_correctly_content_id_cumsum_pct</code></li>\n",
    "                                        <li><code>answered_correctly_cumsum10</code></li>\n",
    "                                        <li><code>answered_correctly_cumsum_pct</code></li>\n",
    "                                        <li><code>answered_correctly_rollsum_pct</code></li>\n",
    "                                        <li><code>answered_incorrectly_content_id_cumsum</code></li>\n",
    "                                        <li><code>lectures_cumcount</code></li>\n",
    "                                        <li><code>prior_question_elapsed_time_rollavg</code></li>\n",
    "                                    </ul>\n",
    "                                </li>\n",
    "                                <li>Single model, single fold</li>\n",
    "                                <li>No public leaderboard - efficient inference in progress</li>\n",
    "                                <li>Refactored code to move queries and helper functions into\n",
    "                                    separate modules</li>\n",
    "                                <li>Completed set up to commit code to Github from Colab and</li>\n",
    "                                <li>Completed set up to push kernels to Kaggle from Colab</li>\n",
    "                            </ul>\n",
    "                        </td>\n",
    "                    </tr>\n",
    "                    <tr>\n",
    "                        <td class=\"{style_cell}\">37</td>\n",
    "                        <td class=\"{style_cell}\">2020-11-04</td>\n",
    "                        <td class=\"{style_cell}\">0.751</td>\n",
    "                        <td class=\"{style_cell}\">0.748</td>\n",
    "                        <td>\n",
    "                            <ul>\n",
    "                                <li>Features added:\n",
    "                                    <ul>\n",
    "                                        <li><code>answered_correctly_cumsum</code></li>\n",
    "                                        <li><code>answered_correctly_rollsum</code></li>\n",
    "                                        <li><code>answered_incorrectly_cumsum</code></li>\n",
    "                                        <li><code>answered_incorrectly_rollsum</code></li>\n",
    "                                        <li><code>part</code></li>\n",
    "                                        <li><code>part_correct_pct</code></li>\n",
    "                                        <li><code>question_id_correct_pct</code></li>\n",
    "                                        <li><code>tag__0</code></li>\n",
    "                                        <li><code>tag__0_correct_pct</code></li>\n",
    "                                    </ul>\n",
    "                                </li>\n",
    "                                <li>Single model, single fold</li>\n",
    "                                <li>Model for public leaderboard didn't include\n",
    "                                    rolling features - still working out how to\n",
    "                                    efficiently calculate for inference</li>\n",
    "                            </ul>\n",
    "                        </td>\n",
    "                    </tr>\n",
    "                </table>\n",
    "            </div>\n",
    "        </div>\n",
    "        <p>\n",
    "            <a href=\"https://colab.research.google.com/github/CalebEverett/riiid_2020/blob/master/riiid-2020.ipynb\" target=\"_blank\" rel=\"nofollow\">\n",
    "            <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
    "        </p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "    html = HTML(html_str)\n",
    "    display(html)\n",
    "show_version_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QCO0cr_juQA",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1mQ0DiRnfer"
   },
   "source": [
    "This kernel is an end to end pipeline that uses BigQuery to store data and perform feature engineering, and trains a model using XGBoost. I was resorting to breaking up tables and still waiting a long time to see the results of my analysis and to process my engineered features, so I decided to learn about BigQuery. This kernel is the current state of my setup, which is working very well. It is much faster than my previous local setup, even with having to download files. It also is making it easier to keep the structure of the data and and code clean, which in turn makes it easier to stay focused on thinking about and executing ideas without getting bogged down waiting for things to finish or wading through extraneous processing code.\n",
    "\n",
    "I've attempted to put  this book together in such a way that somebody else can fork it, update a few environment variables, run it and then be in the game engineering features and improving the model. The only requirements are a GCP project and storage bucket. Other than that, it is turn key, starting with creating a BigQuery dataset and ending with a saved model and two feature tables that get uploaded to a Kaggle dataset where they are used in a separate kernel to make predictions and submit to the competition api.\n",
    "\n",
    "A couple of cool features:\n",
    "* Uses the gcs version of the competition datset to create a dataset and upload to BigQuery in around a minute\n",
    "* Transformations get run on the entire train table at once and run in under 10 minutes\n",
    "* Feature engineering gets done on a sample of the train table, taking advantage of BigQuery' graphical query editing interface that includes tab completion, syntax checking and the ability to run queries and inspect results\n",
    "* Stores queries as methods on a dedicated class, where they can be easily reused\n",
    "* Dtypes for local dataframes, schema for BigQuery tables and all tranformations are maintained locally so that the transformed tables can be recreated from the original competition dataset files automatically at any time (see description of workflow below to continue with this practice)\n",
    "* Exports to gcs using temporary tables created by BigQuery avoiding unnecessary storage and wasted time rerunning and exporting duplicate queries\n",
    "* Separate [submission kernel](https://www.kaggle.com/calebeverett/riiid-submit) uses sqlite3 to achieve sub two hour submission times while maintaining state for questions, users and user-content (80+ million rows)\n",
    "\n",
    "I've engineered a few features as a starting point to demonstrate how additional features can be efficiently developed and processed, including:\n",
    "* Cumulative and rolling sums of questions answered correctly and incorrectly by user\n",
    "* Percent of questions answered correctly by question id, part and the first question tag\n",
    "\n",
    "The model is also just a starting point, with a first pass at a train/validation split and no hyperparameter tuning. I have included some basic diagnostics on both the train/validtion split and model performance as a starting place for further development. Trained on a small subset of the overall training data with a small number of engineered features, it is producing a local validation AUC score of around 0.75 and slighly less than that on the public leaderboard.\n",
    "\n",
    "I have the table creation and transformation functions set to not run, but you can set them to run, by changing the flags to `True` for:\n",
    "* Loading tables - one flag for the questions table and another for the train and lectures tables\n",
    "* Updating the schemas in BigQuery\n",
    "* Performing the transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "savju5R9juQB",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Resources\n",
    "* [BigQuery Console](https://console.cloud.google.com/bigquery)\n",
    "* [Python Client for Google BigQuery](https://googleapis.dev/python/bigquery/latest/index.html)\n",
    "* [Analytic function concepts in Standard SQL](https://cloud.google.com/bigquery/docs/reference/standard-sql/analytic-function-concepts)\n",
    "* [XGBoost Documentation](https://xgboost.readthedocs.io/en/latest/index.html)\n",
    "* [Storge Client](https://googleapis.dev/python/storage/latest/client.html)\n",
    "* [pandas documentation](https://pandas.pydata.org/docs/)\n",
    "* [Plotly Python Open Source Graphing Library](https://plotly.com/python/)\n",
    "* [PEP 8 -- Style Guide for Python Code](https://www.python.org/dev/peps/pep-0008/)\n",
    "* [Comet.ml Experiment API](https://www.comet.ml/docs/python-sdk/Experiment/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88t93RZzj982",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "tKe4S7M4nbSU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\n",
      "\n",
      "Git global user.name and user.email set.\n"
     ]
    }
   ],
   "source": [
    "# <hide-input>\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from google.cloud import storage, bigquery\n",
    "from google.cloud.bigquery import SchemaField\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "BUCKET = 'riiid-caleb'\n",
    "DATASET = 'data'\n",
    "LOCATION = 'US'\n",
    "KAGGLE_SUBMIT_DATASET = 'riiid-submission-private'\n",
    "PROJECT = 'riiid-caleb'\n",
    "REPO = 'riiid_2020'\n",
    "NOT_KAGGLE = os.getenv('KAGGLE_URL_BASE') is None\n",
    "\n",
    "# if NOT_KAGGLE:\n",
    "#     from google.colab import drive\n",
    "#     DRIVE = Path('/content/drive/My Drive')\n",
    "#     if not DRIVE.exists():\n",
    "#         drive.mount(str(DRIVE.parent))\n",
    "#     sys.path.append(str(DRIVE))\n",
    "#     g_creds_path = 'credentials/riiid-caleb-faddd0c9d900.json'\n",
    "#     os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = str(DRIVE/g_creds_path)\n",
    "\n",
    "bucket = storage.Client(project=PROJECT).get_bucket(BUCKET)\n",
    "dataset = bigquery.Dataset(f'{PROJECT}.{DATASET}')\n",
    "bq_client = bigquery.Client(project=PROJECT, location=LOCATION)\n",
    "\n",
    "if NOT_KAGGLE:\n",
    "    CONFIG = json.loads(bucket.get_blob('config.json').download_as_string())\n",
    "    os.environ = {**os.environ, **CONFIG}\n",
    "    sys.path.append('/home')\n",
    "    from riiid_2020.utilities import check_packages, Git\n",
    "    from riiid_2020.bqhelpers import BQHelper\n",
    "    from riiid_2020.queries import Queries\n",
    "    \n",
    "    git = Git(REPO, CONFIG.get('GIT_USERNAME'), CONFIG.get('GIT_PASSWORD'),\n",
    "              CONFIG.get('EMAIL'), Path())\n",
    "\n",
    "#     packages = {\n",
    "#         'comet-ml': '3.2.5',\n",
    "#         'gcsfs': '0.7.1',\n",
    "#         'kaggle': '1.5.9',\n",
    "#         'plotly': '4.12.0',\n",
    "#         'xgboost': '1.2.0',\n",
    "#     }\n",
    "#     check_packages(packages)\n",
    "\n",
    "    from comet_ml import APIExperiment, Experiment\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "    kaggle_api = KaggleApi()\n",
    "    kaggle_api.authenticate()\n",
    "\n",
    "import lightgbm as lgb\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import xgboost as xgb\n",
    "pd.options.plotting.backend = 'plotly'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3I6-yy4QBxlR",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Modules\n",
    "Included in notebook for convenience when in a Kaggle kernel. Github repo [here](https://github.com/CalebEverett/riiid_2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--uRkD6w0EhS"
   },
   "outputs": [],
   "source": [
    "# <include-bqhelpers.py><hide-input>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dTP7zTkV0qhK"
   },
   "outputs": [],
   "source": [
    "# <include-queries.py><hide-input>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWx9otMx1O2Y"
   },
   "outputs": [],
   "source": [
    "# <include-utilities.py><hide-input>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4nP2GeV09FG"
   },
   "outputs": [],
   "source": [
    "# <include-config.json><hide-input><hide-output>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "WO6DVIxuQydR"
   },
   "outputs": [],
   "source": [
    "Q = Queries(DATASET)\n",
    "bqh = BQHelper(bucket, DATASET, bq_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4KCDUqQwISk"
   },
   "outputs": [],
   "source": [
    "git.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cs6bXr35juQM",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Create BigQuery Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVloHU3wjuQQ"
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    delete_contents=False\n",
    "    bq_client.delete_dataset(DATASET, delete_contents=delete_contents)\n",
    "    print(f'Dataset {dataset.dataset_id} deleted from project {dataset.project}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2-E_hTejuQO"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    dataset = bq_client.get_dataset(dataset.dataset_id)\n",
    "    print(f'Dataset {dataset.dataset_id} already exists '\n",
    "          f'in location {dataset.location} in project {dataset.project}.')\n",
    "except:\n",
    "    dataset = bq_client.create_dataset(dataset)\n",
    "    print(f'Dataset {dataset.dataset_id} created '\n",
    "          f'in location {dataset.location} in project {dataset.project}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HItb6CWGjuQS",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Load Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjTuu8CJjuQT"
   },
   "source": [
    "### Dataframe dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "8dxMzeCsjuQT"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "dtypes_orig = {\n",
    "    'lectures': {\n",
    "        'lecture_id': 'uint16',\n",
    "        'tag': 'uint8',\n",
    "        'part': 'uint8',\n",
    "        'type_of': 'str',\n",
    "    },\n",
    "    'questions': {\n",
    "        'question_id': 'uint16',\n",
    "        'bundle_id': 'uint16',\n",
    "        'correct_answer': 'uint8',\n",
    "        'part': 'uint8',\n",
    "        'tags': 'str',\n",
    "        \n",
    "    },\n",
    "    'train': {\n",
    "        'row_id': 'int64',\n",
    "        'timestamp': 'int64',\n",
    "        'user_id': 'int32',\n",
    "        'content_id': 'int16',\n",
    "        'content_type_id': 'int8',\n",
    "        'task_container_id': 'int16',\n",
    "        'user_answer': 'int8',\n",
    "        'answered_correctly': 'int8',\n",
    "        'prior_question_elapsed_time': 'float32', \n",
    "        'prior_question_had_explanation': 'bool',\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "dtypes_new = {\n",
    "    'lectures': {},\n",
    "    'questions': {},\n",
    "    'train': {\n",
    "        'ql_id': 'int16',\n",
    "        'fold': 'int8',\n",
    "        'lectures_cumcnt': 'int16',\n",
    "        'lectures_cumcnt_part': 'int16',\n",
    "        'lectures_cumcnt_tag_0': 'int16',\n",
    "        'lectures_cumcnt_tags': 'int16',\n",
    "        'lectures_cumcnt_session': 'int16',\n",
    "        'task_container_id_orig': 'int16',\n",
    "        'ts_minute': 'int16',\n",
    "        'session_minute_max': 'int16',\n",
    "        'pqet_sec': 'int16',\n",
    "        'pqet_sec_rollavg': 'int16',\n",
    "        'session': 'uint8',\n",
    "        'r_cumcnt_clip': 'int16'\n",
    "    }\n",
    "}\n",
    "\n",
    "dtypes_content_tags = {\n",
    "    'ql_id': 'int16',\n",
    "    'question_id': 'int16',\n",
    "    'lecture_id': 'int16',\n",
    "    'bundle_id': 'uint16',\n",
    "    'correct_answer': 'uint8',\n",
    "    'part': 'int8',\n",
    "    'tags': 'str',\n",
    "    'tags_array': 'str',\n",
    "    'tag_0': 'uint8',\n",
    "    'part_correct_pct': 'int8',\n",
    "    'tag_0_correct_pct': 'int8',\n",
    "    'question_id_correct_pct': 'int8',\n",
    "    'tags_correct_pct': 'int8',\n",
    "    'tags_code': 'int16'\n",
    "}\n",
    "\n",
    "# each of these gets cumsums for correct and\n",
    "# incorrect, row count and pct correct\n",
    "cumsum_cols = {\n",
    "    'ac_cumsum': 'int16',\n",
    "    'ac_cumsum_content_id': 'int16',\n",
    "    'ac_cumsum_part': 'int16',\n",
    "    'ac_cumsum_session': 'int16',\n",
    "    'ac_cumsum_tag_0': 'int16',\n",
    "    'ac_cumsum_tags': 'int16',\n",
    "    'ac_cumsum_upto': 'int8',\n",
    "}\n",
    "\n",
    "for c, t in cumsum_cols.items():\n",
    "    dtypes_new['train'][c] = t\n",
    "    r_col = c.replace('ac_cumsum', 'r_cumcnt')\n",
    "    dtypes_new['train'][r_col] = t\n",
    "    i_col = c.replace('ac_cumsum', 'aic_cumsum')\n",
    "    dtypes_new['train'][i_col] = t\n",
    "    p_col = c.replace('ac_cumsum', 'ac_cumsum_pct')\n",
    "    dtypes_new['train'][p_col] = 'int8'\n",
    "\n",
    "dtypes = {}\n",
    "for table_id in dtypes_orig:\n",
    "    dtypes[table_id] = {\n",
    "        **dtypes_orig[table_id],\n",
    "        **dtypes_new[table_id]\n",
    "    }\n",
    "\n",
    "dtypes = {\n",
    "    **dtypes['train'],\n",
    "    **dtypes_content_tags\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhPzQmvUjuQV",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### BigQuery Table Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WdW0igS4juQW"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "type_map = {\n",
    "    'int64': 'INTEGER',\n",
    "    'int32': 'INTEGER',\n",
    "    'int16': 'INTEGER',\n",
    "    'int8': 'INTEGER',\n",
    "    'uint8': 'INTEGER',\n",
    "    'uint16': 'INTEGER',\n",
    "    'str': 'STRING',\n",
    "    'bool': 'BOOL',\n",
    "    'float32': 'FLOAT'\n",
    "}\n",
    "\n",
    "schemas_orig = {table: [SchemaField(f, type_map[t]) for f, t in\n",
    "                   fields.items()] for table, fields in dtypes_orig.items()}\n",
    "\n",
    "schemas = {}\n",
    "for table_id, fields in dtypes_new.items():\n",
    "    new_fields = [SchemaField(f, type_map[t]) for\n",
    "                  f, t in fields.items()]\n",
    "    schemas[table_id] = schemas_orig[table_id] + new_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOpOrtr9juQY",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### Load Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "saboKI_rjuQc"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "# Load questions from local json file - can't load tags as array from csv.\n",
    "\n",
    "# only reason to use this is if using one-hot tags\n",
    "if False:\n",
    "    bqh.del_table('questions')\n",
    "    \n",
    "    df_questions = pd.read_csv(f'gs://{BUCKET}/questions.csv')\n",
    "    df_questions.tags = df_questions.tags.fillna('189')\n",
    "    df_questions.tags = df_questions.tags.str.split()\n",
    "    \n",
    "    if one_hot_tags:\n",
    "        mlb = MultiLabelBinarizer()\n",
    "        one_hots = (mlb.fit_transform(df_questions.tags\n",
    "                    .apply(lambda l: [f'tag_{int(t):03d}' for t in l])))\n",
    "        df_one_hots = pd.DataFrame(one_hots, columns = mlb.classes_)\n",
    "        df_questions = pd.concat([df_questions, df_one_hots], axis=1)\n",
    "    \n",
    "    df_questions.to_json('questions.json', orient=\"records\", lines=True)\n",
    "    lj = bqh.load_json_file('questions', schemas).result()\n",
    "\n",
    "# tags to array logic moved to sql, ok to load csv directly\n",
    "# doesn't create one-hot tags\n",
    "if False:\n",
    "    bqh.del_table('questions')\n",
    "    lj = bqh.load_csv_uri('questions', schemas_orig).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XXwb4YkWjuQe"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "if False:\n",
    "    for table_id in dtypes_orig:\n",
    "        bqh.del_table(table_id)\n",
    "        lj = bqh.load_csv_uri(table_id, schemas_orig).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHkK8JhQjuQg"
   },
   "outputs": [],
   "source": [
    "# <hide-input><hide-output>\n",
    "df_jobs = bqh.get_df_jobs()\n",
    "df_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdk5EpmsQ7Pl"
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    job = bq_client.get_job(df_jobs.iloc[1].job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cGVHAtMjuQi"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "df_table_list = bqh.get_df_table_list()\n",
    "df_table_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgTZkanIjuQk"
   },
   "source": [
    "### Update Table Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_t7T4NftjuQk"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "if False:\n",
    "    for table_id, schema in schemas.items():\n",
    "        table = bqh.get_table(table_id)\n",
    "        table.schema = schema\n",
    "        table = bq_client.update_table(table, ['schema'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ouoo1oQCjuQm",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Engineer Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CU8m9kx9juQn"
   },
   "source": [
    "A good workflow here is:\n",
    "* Create a sample of the train table.\n",
    "* Use the BigQuery query editor user interface to get the SQL for a new feature worked out as a selection from the `train_sample` table. The user interface there has tab completion, syntax checking and displays results, which makes creating and debugging queries a snap.\n",
    "    * [BigQuery Console](https://console.cloud.google.com/bigquery?project=riiid-caleb) (Update project query string for your project.)\n",
    "    * [BigQuery Query syntax in Standard SQL](https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax) is your friend.\n",
    "* Optional: create a local dataframe, using the export functions below, to confirm that it is working the right way.\n",
    "* Add a column to the appropriate table by adding a value to `dtypes_new`\n",
    "* Update the schema for the table in BigQuery by running the Update Table Schemas cell above\n",
    "* Recreate the `train_sample` table by running the cell below.\n",
    "* Use the BigQuery query editor user interface add the logic to update the new column.\n",
    "* Optional: create a local dataframe, using the export functions below, to confirm that the update is working the right way.\n",
    "* Copy the SQL to a new method in the `Queries` class above\n",
    "* Add the query to the appropriate `run_transformations` function above\n",
    "* Run transformations on `train_sample` table\n",
    "* Inspect `train_sample` table in BigQuery to confirm everything is working correctly\n",
    "* Optional: load load local dataframe using `get_df_query` function for further inspection\n",
    "* Run transformations on `train` table\n",
    "* Inspect `train` table in BigQuery to confirm everything is working correctly\n",
    "* Optional: load local dataframe using `get_df_query` function for further inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfKY_WsvjuQp"
   },
   "source": [
    "### Perform Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOnBP6sfjuQp"
   },
   "source": [
    "#### Train Table\n",
    "* Update task_container_id to increase monotonically with timestamp\n",
    "    * There were some `task_conatiner_id`s that were out of order with respect to timestamp. They needed to be be ordered correctly so that cumulative and rolling sums partitioned by `task_container_id` would be include only interactions with earlier `timestamps`. Even though all interactions with the same `task_container_id` have the same `timestamp`, partioning by `timestamp` is much slower (because the range of values is so much wider?).\n",
    "* Calc answered_incorrectly\n",
    "    * `answered_correctly` for lectures was recorded as -1 and needed to be set to 0 to calculate cumulative and rolling sums correctly including lectures. As a consequence, `answered_incorrectly` could be calculated as the inverse of `answered_correctly`.\n",
    "* Calc cumsum for `answered_correctly` and `answered_incorrectly` by `user_id` and by `user_id` and `content_id` and rolling avg for `prior_question_elapsed_time` by user \n",
    "    * This is done so that the totals are as of the preceding `task_container_id`\n",
    "* Calculate rolling sum for `answered_correctly` and `answered_incorrectly` by `user_id`\n",
    "    * Includes the 10 rows preceding the current `task_container_id`\n",
    "    * I couldn't figure out how to get this done with the standard window functionality since I wanted a set number of rows preceding the current task container (as opposed to just the current row), so it joins on `user_id` with a `task_container_id` less than the current one, which takes a while to complete.\n",
    "* Calculate answered correctly percentages for `answered_correctly_cumsum`, `answered_correctly_rollsum` and `answered_correctly_content_id_cumsum_pct`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p56xi-SBW8-N"
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    q = Q.update_train_window_containers_time(table_id='train')\n",
    "    qj = bqh.run_query(*q, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r2LZdBETjuQs"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "def run_train_transforms(table_id=None):\n",
    "    # Run serially to avoid update conflicts\n",
    "    \n",
    "    train_queries = [\n",
    "        Q.update_ql_id(table_id=table_id),\n",
    "        Q.update_task_container_id(table_id=table_id),\n",
    "        Q.update_missing_values(table_id=table_id,\n",
    "                                column_id='prior_question_had_explanation',\n",
    "                                value='false'),\n",
    "        Q.update_missing_values(table_id=table_id,\n",
    "                                column_id='prior_question_elapsed_time',\n",
    "                                value='0'),\n",
    "        Q.update_answered_correctly(table_id=table_id),\n",
    "        Q.update_train_window_containers_pqet(table_id=table_id),\n",
    "        Q.update_train_window_containers_session(table_id=table_id, session_hours=72),\n",
    "        Q.update_train_window_containers(table_id=table_id),\n",
    "        Q.update_train_window_containers_tag_0(table_id=table_id),\n",
    "        Q.update_train_window_containers_tags(table_id=table_id),\n",
    "        Q.update_answered_correctly_cumsum_upto(table_id=table_id)\n",
    "    ]\n",
    "\n",
    "    train_queries_not_run = [\n",
    "        Q.update_train_window_rows(table_id=table_id, window=10)\n",
    "    ]\n",
    "    \n",
    "    _ = [bqh.run_query(*q, wait=True) for q in train_queries]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JEU6G0hMLkP"
   },
   "source": [
    "#### Questions Table\n",
    "* Calculate percent answered correctly for `question_id`, `part` and `tag__0`\n",
    "* Add question columns\n",
    "    * Adding question part and the first associated tag. (There wasn't any official information regarding the order of the tags as recorded for each question, but they did not appear to be sorted so it seems possible the order in which they are recorded is significant.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jG596OjGtm5Y"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "def run_questions_transforms_before():\n",
    "    \"\"\"These have to be run BEFORE the transforms are run on the full\n",
    "    train table.\n",
    "    \"\"\"\n",
    "    \n",
    "    questions_queries = [Q.update_missing_values('questions', 'tags', '\"189\"'),\n",
    "                         Q.create_table_content_tags()]\n",
    "    \n",
    "    _ = [bqh.run_query(*q, wait=True).result() for q in questions_queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Ay24JcgjuQv"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "def run_questions_transforms_after():\n",
    "    \"\"\"These have to be run AFTER the transforms are run on the full\n",
    "    train table.\n",
    "    \"\"\"\n",
    "    questions_queries = []\n",
    "    for column_id in ['question_id', 'part', 'tag_0', 'tags']:\n",
    "        questions_queries.append(Q.update_content_tags_correct_pct(column_id))\n",
    "    \n",
    "    _ = [bqh.run_query(*q, wait=True).result() for q in questions_queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tuh_k3VfjuQx"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "if False:\n",
    "    run_questions_transforms_before()\n",
    "    # run_train_transforms('train')\n",
    "    run_questions_transforms_after()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTG_h2a2juQy"
   },
   "source": [
    "### Check Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12-1u5TdjuQ1"
   },
   "outputs": [],
   "source": [
    "query = Q.select_train(table_id='train', excl_lectures=True)\n",
    "df_query = bqh.get_df_query(query, dtypes=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ub-U0nPgjuQ3"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "cols = [\n",
    "        'row_id',\n",
    "        'task_container_id_orig',\n",
    "        'timestamp',\n",
    "        'content_type_id',\n",
    "        'user_id',\n",
    "        'task_container_id',\n",
    "        'part',\n",
    "        'tag__0',\n",
    "        'answered_correctly',\n",
    "        'answered_incorrectly',\n",
    "        'answered_correctly_cumsum',\n",
    "        'answered_incorrectly_cumsum',\n",
    "        'answered_correctly_content_id_cumsum',\n",
    "        'answered_correctly_rollsum',\n",
    "        'answered_incorrectly_rollsum',\n",
    "        'answered_incorrectly_content_id_cumsum',\n",
    "        'part_correct_pct',\n",
    "        'tag__0_correct_pct',\n",
    "        'question_id_correct_pct',\n",
    "        'prior_question_elapsed_time',\n",
    "        'prior_question_elapsed_time_rollavg',\n",
    "        'prior_question_had_explanation',\n",
    "        'lectures_cumcount',\n",
    "        'answered_correctly_cumsum_upto'\n",
    "]\n",
    "\n",
    "df_user = df_query[cols].copy()\n",
    "df_user.timestamp = df_user.timestamp / (1000*60*60)\n",
    "\n",
    "df_user.loc[df_user.user_id == 44331].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zO6GM_CLjuQ5"
   },
   "source": [
    "### Visually Inspect Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jpokxssbjuQ6"
   },
   "source": [
    "The charts below can also be used to visually inspect whether the transformations have been performed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0c-xlk2TjuQ6"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "groups = {\n",
    "    'cum': {\n",
    "        'columns': {\n",
    "            'task_container_id': 0,\n",
    "            'answered_correctly_cumsum': 2,\n",
    "            'answered_incorrectly_cumsum': 1\n",
    "        },\n",
    "        'xaxis': 'elapsed_hours'\n",
    "    },\n",
    "    'roll': {\n",
    "        'columns': {\n",
    "            'answered_correctly_rollsum': 2,\n",
    "            'answered_correctly': 7,\n",
    "            'answered_incorrectly_rollsum': 1,\n",
    "            'answered_incorrectly': 8,\n",
    "            'part': 9\n",
    "        },\n",
    "        'xaxis': 'row_id'\n",
    "    },  \n",
    "    'correct_pct': {\n",
    "        'columns': {\n",
    "            'question_id_correct_pct': 0,\n",
    "            'part_correct_pct': 5,\n",
    "            'tag__0_correct_pct': 6\n",
    "        },\n",
    "        'xaxis': 'row_id'\n",
    "    },  \n",
    "    'prior_question_elapsed_time': {\n",
    "        'columns': {\n",
    "            'prior_question_elapsed_time': 0,\n",
    "        },\n",
    "        'xaxis': 'row_id'\n",
    "    },  \n",
    "    'prior_question_had_explanation': {\n",
    "        'columns': {\n",
    "            'prior_question_had_explanation': 0,\n",
    "        },\n",
    "        'xaxis': 'row_id'\n",
    "    }\n",
    "}\n",
    "\n",
    "def plot_user_learning(user_id=None, group=None, suffix=None):\n",
    "    theme = px.colors.qualitative.Plotly\n",
    "    columns = list(group['columns'].keys())\n",
    "    colors = [theme[c] for c in group['columns'].values()]\n",
    "\n",
    "    df_query['elapsed_hours'] = df_query.timestamp / (1000*60*60)\n",
    "\n",
    "    df = (df_query.loc[(df_user.user_id == user_id) &\n",
    "                       (df_user.content_type_id == 0)])\n",
    "\n",
    "    # labels = {'value': 'answer count'}\n",
    "\n",
    "    fig = df.plot(x=group['xaxis'], y=columns, color_discrete_sequence=colors,\n",
    "                  title=f'Learning Progress - user_id = {user_id} - {suffix}')\n",
    "    fig.data\n",
    "\n",
    "    return fig\n",
    "\n",
    "user_id_random = np.random.choice(df_query.user_id.unique(), (1,))[0]\n",
    "use_random = False\n",
    "user_id =  user_id_random if use_random else 5382\n",
    "\n",
    "for k, v in groups.items():\n",
    "    fig = plot_user_learning(user_id, v, k)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Axb2oD77juRM"
   },
   "source": [
    "### Create Folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNsk1_JsjuRN"
   },
   "source": [
    "The objectives for the validation split are as follows:\n",
    "* Include some users that don't exist in the training set\n",
    "* Include records for some users in the validation set with timestamps greater than all of those users' records in the training set\n",
    "\n",
    "This is achieved by first setting the percentage of users that will only occur in the training set and then setting the percentage of the remaining users that will have records in both.\n",
    "\n",
    "The split between the validation and training sets for the users with records in both is determined by randomly selecting a number between zero and the maximum task_container_id for each user and including in the validation set all records with a task_container_id greater than that for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_nmEi_1gMFf"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "# create validation split table\n",
    "# this needs to run after the task container Ids have been updated\n",
    "\n",
    "table_id_folds = 'folds'\n",
    "if True:\n",
    "    qj = bqh.run_query(*Q.create_table_folds(table_id=table_id_folds), wait=True)\n",
    "    qj = bqh.run_query(*Q.update_folds(table_id_folds=table_id_folds), wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PX-J3AaG5FxM"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "# TODO: bring in diagnostic charts from folding is fun\n",
    "if False:\n",
    "    df_folds = bqh.get_df_table('folds', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GBDKOZ2juRA"
   },
   "source": [
    "With feature engineering being performed in BigQuery, data has to be exported to train models locally. The [Python Client for Google BigQuery](https://googleapis.dev/python/bigquery/latest/index.html) [to_dataframe()](https://googleapis.dev/python/bigquery/latest/generated/google.cloud.bigquery.job.QueryJob.html?highlight=to_dataframe#google.cloud.bigquery.job.QueryJob.to_dataframe) makes it possible to create dataframes directly, but is prohibitively slow for large datasets. While it is not possible to export table directly to the local file system, it is possible to export to cloud storage and then download locally from there. This is reasonably efficient, taking a couple of minutes to run a query, export to cloud storage, download to the local file system and then read the files into a dataframe. The is another api, the [BigQuery Storage API](https://cloud.google.com/bigquery/docs/reference/storage), that a client can be created with that is really fast and works with the `to_dataframe` method, but unforunatley it isn't working with the current Kaggle kernel environment.\n",
    "\n",
    "The functions below take advantage of the fact BigQuery stores queries in temporary tables so that preveiously requested queries can be retrieved without having to run them again. Similarly, the functions below name the exported files with the reference to the BigQuery temporary table, so that if a function is run to create a dataframe from a query for which the files already exist in cloud storage or locally, they won't be exported or downloaded again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_B3C-9QjuQ9"
   },
   "source": [
    "### Create Sample of Train Table for R&D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tuNFCT1OjuQ9"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "if False:\n",
    "    ts_id = 'train_sample'\n",
    "    bqh.del_table(ts_id)\n",
    "    bqh.run_query(*Q.create_train_sample(ts_id), wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbaxOZFVjuRA",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Create Local Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMqolxVmjuRL"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xV-qHbTc2oly"
   },
   "source": [
    "### Select Features to Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "rnDz1XqY5g-n"
   },
   "outputs": [],
   "source": [
    "# <hide-input><hide-output>\n",
    "if False:\n",
    "    feats = sorted([f\"\"\"'{k+\"':\":<32} {v},\"\"\" for k,v in features.items()])\n",
    "    for f in feats:\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "QUkacRjajuRG"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "features = {\n",
    "    'ac_cumsum':                      [True, True],\n",
    "    'ac_cumsum_content_id':           [True, True],\n",
    "    'ac_cumsum_part':                 [True, True],\n",
    "    'ac_cumsum_pct':                  [True, True],\n",
    "    'ac_cumsum_pct_content_id':       [True, True],\n",
    "    'ac_cumsum_pct_part':             [True, True],\n",
    "    'ac_cumsum_pct_session':          [True, True],\n",
    "    'ac_cumsum_pct_tag_0':            [True, True],\n",
    "    'ac_cumsum_pct_tags':             [True, True],\n",
    "    'ac_cumsum_pct_upto':             [True, True],\n",
    "    'ac_cumsum_session':              [True, True],\n",
    "    'ac_cumsum_tag_0':                [True, True],\n",
    "    'ac_cumsum_tags':                 [True, True],\n",
    "    'ac_cumsum_upto':                 [True, True],\n",
    "    'aic_cumsum':                     [True, True],\n",
    "    'aic_cumsum_content_id':          [True, True],\n",
    "    'aic_cumsum_part':                [True, True],\n",
    "    'aic_cumsum_session':             [True, True],\n",
    "    'aic_cumsum_tag_0':               [True, True],\n",
    "    'aic_cumsum_tags':                [True, True],\n",
    "    'aic_cumsum_upto':                [True, True],\n",
    "    'bundle_id':                      [False, False],\n",
    "    'answered_correctly':             [True, False],\n",
    "    'content_id':                     [True, False],\n",
    "    'content_type_id':                [True, False],\n",
    "    'correct_answer':                 [True, True],\n",
    "    'fold':                           [True, False],\n",
    "    'lecture_id':                     [False, False],\n",
    "    'lectures_cumcnt':                [True, True],\n",
    "    'lectures_cumcnt_part':           [True, True],\n",
    "    'lectures_cumcnt_session':        [True, True],\n",
    "    'lectures_cumcnt_tag_0':          [True, True],\n",
    "    'lectures_cumcnt_tags':           [True, True],\n",
    "    'part':                           [True, True],\n",
    "    'part_correct_pct':               [True, True],\n",
    "    'pqet_sec':                       [True, True],\n",
    "    'pqet_sec_rollavg':               [True, False],\n",
    "    'prior_question_elapsed_time':    [True, True],\n",
    "    'prior_question_had_explanation': [True, True],\n",
    "    'ql_id':                          [False, False],\n",
    "    'question_id':                    [False, False],\n",
    "    'question_id_correct_pct':        [True, True],\n",
    "    'r_cumcnt':                       [True, True],\n",
    "    'r_cumcnt_clip':                  [True, True],\n",
    "    'r_cumcnt_content_id':            [True, True],\n",
    "    'r_cumcnt_part':                  [True, True],\n",
    "    'r_cumcnt_session':               [True, True],\n",
    "    'r_cumcnt_tag_0':                 [True, True],\n",
    "    'r_cumcnt_tags':                  [True, True],\n",
    "    'r_cumcnt_upto':                  [True, True],\n",
    "    'row_id':                         [True, False],\n",
    "    'session':                        [True, True],\n",
    "    'session_minute_max':             [True, False],\n",
    "    'tag_0':                          [True, True],\n",
    "    'tag_0_correct_pct':              [True, True],\n",
    "    'tags':                           [True, False],\n",
    "    'tags_array':                     [False, False],\n",
    "    'tags_code':                      [True, True],\n",
    "    'tags_correct_pct':               [True, True],\n",
    "    'task_container_id':              [True, False],\n",
    "    'task_container_id_orig':         [False, False],\n",
    "    'timestamp':                      [True, True],\n",
    "    'ts_minute':                      [True, True],\n",
    "    'user_answer':                    [True, False],\n",
    "    'user_id':                        [True, False]\n",
    " }\n",
    "\n",
    "columns_export = [f for f, v in features.items() if v[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "32Wt1DvjpnJZ"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "def get_features_widget(features_dict, columns_list, idx):\n",
    "\n",
    "    names = []\n",
    "    widget_list = []\n",
    "    for key, v in features_dict.items():\n",
    "        widget_list.append(widgets.ToggleButton(value=v[idx],\n",
    "                                                description=key,\n",
    "                                                layout={'width': '290px'},\n",
    "                                                button_style='primary'))\n",
    "        names.append(key)\n",
    "\n",
    "    arg_dict = {names[i]: widget for i, widget in enumerate(widget_list)}\n",
    "\n",
    "    layout = widgets.Layout(grid_template_columns=\"repeat(3, 300px)\")\n",
    "    ui = widgets.GridBox(widget_list, layout=layout)\n",
    "\n",
    "    def select_data(**kwargs):\n",
    "        columns_list.clear()\n",
    "\n",
    "        for key in kwargs:\n",
    "            features_dict[key][idx] = False\n",
    "            if kwargs[key]:\n",
    "                columns_list.append(key)\n",
    "                features_dict[key][idx] = True\n",
    "\n",
    "        print(f'{len(columns_list)} columns selected')\n",
    "\n",
    "    output = widgets.interactive_output(select_data, arg_dict)\n",
    "    return ui, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "B6ddqQ4HBT3R"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2ec34fa9954c07a0c6c37ef9c065ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(ToggleButton(value=True, button_style='info', description='ac_cumsum', layout=Layout(width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f41d85ec3f455d89ede152d9854196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# <hide-input>\n",
    "display(*get_features_widget(features, columns_export, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "EXRXQ86UjuRK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job select_train_89563f66-a972-48e3-b12d-4c402353d7d0 started.\n",
      "Job select_train_89563f66-a972-48e3-b12d-4c402353d7d0 finished in 0.074 seconds.\n",
      "52 files already exist in gcs with prefix tables/anon78a3f5084fee818ffb629a25c95acb07ef8b2a4f.\n",
      "52 files already exist locally for table tables/anon78a3f5084fee818ffb629a25c95acb07ef8b2a4f.\n",
      "Creating dataframe from 52 files for table tables/anon78a3f5084fee818ffb629a25c95acb07ef8b2a4f...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3ff96342ab4cc5b34c139312d5edf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Files Read: ', max=52.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataframe finished for train table at tables/anon78a3f5084fee818ffb629a25c95acb07ef8b2a4f with 59 columns and 25,510,100 rows.\n",
      "CPU times: user 2min 37s, sys: 15.2 s, total: 2min 52s\n",
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# <hide-output>\n",
    "if True:\n",
    "    folds = list(range(40))\n",
    "    \n",
    "    query = Q.select_train(columns=columns_export, folds=folds,\n",
    "                           excl_lectures=True, limit=None)\n",
    "    \n",
    "    df_train = bqh.get_df_query_gcs(query, dtypes=None, file_format='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "TAIxa0UkIZCF"
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    \n",
    "    base_cols = [\n",
    "            'user_id',\n",
    "            'task_container_id',\n",
    "            'row_id',\n",
    "            'content_id',\n",
    "            'content_type_id',\n",
    "            'prior_question_had_explanation',\n",
    "            'answered_correctly',\n",
    "    ]\n",
    "    \n",
    "    col = 'session'\n",
    "    \n",
    "    cum_cols = [\n",
    "            'ac_cumsum',\n",
    "            'aic_cumsum',\n",
    "            'r_cumcnt',\n",
    "            'r_cumcnt_clip',\n",
    "            'ac_cumsum_pct',\n",
    "            'lectures_cumcnt',\n",
    "            f'ac_cumsum_{col}',\n",
    "            f'aic_cumsum_{col}',\n",
    "            f'r_cumcnt_{col}',\n",
    "            f'ac_cumsum_pct_{col}',\n",
    "            f'lectures_cumcnt_{col}'\n",
    "    ]\n",
    "\n",
    "    q_cols = [\n",
    "              'part',\n",
    "              'tags',\n",
    "              'tag_0',\n",
    "              'question_id_correct_pct',\n",
    "              'part_correct_pct',\n",
    "              'tag_0_correct_pct',\n",
    "              'tags_correct_pct'\n",
    "    ]\n",
    "\n",
    "    time_cols = [\n",
    "            'prior_question_elapsed_time',\n",
    "            'timestamp',\n",
    "            'ts_minute',\n",
    "            'session_minute_max',\n",
    "            'pqet_sec',\n",
    "            'pqet_sec_rollavg',\n",
    "            'session'\n",
    "    ]\n",
    "\n",
    "# df_test = bqh.get_df_query_gcs(('SELECT * FROM data.train t JOIN data.content_tags c ON t.ql_id = c.ql_id WHERE user_id IN (1827855198, 1066383521) ORDER BY user_id, task_container_id, row_id', '_test'), dtypes=None, file_format='json')\n",
    "\n",
    "# df_test[base_cols + cum_cols][df_test.user_id == 1827855198].tail(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VM6n9FKyczN"
   },
   "source": [
    "### Select Columns for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "MUSDoZoLEKP_"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d046f7be1f4b3d8439f130dfe0d3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(ToggleButton(value=True, button_style='primary', description='ac_cumsum', layout=Layout(widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29576f9fbdc74917a3f466e64738787d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# <hide-input>\n",
    "columns_train = []\n",
    "display(*get_features_widget(features, columns_train, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "q-zrGOfDwjw9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_b7f477ba_345f_11eb_a73f_0242ac110002row0_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row0_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row1_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row1_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row2_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row2_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row3_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row3_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row4_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row4_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row5_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row5_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row6_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row7_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row7_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row8_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row8_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row9_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row9_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row10_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row10_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row11_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row11_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row12_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row12_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row13_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row13_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row14_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row14_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row15_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row15_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row16_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row16_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row17_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row17_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row18_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row18_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row19_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row19_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row20_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row20_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row22_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row23_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row24_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row25_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row25_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row26_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row28_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row28_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row29_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row29_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row30_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row30_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row31_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row31_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row32_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row32_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row33_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row33_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row34_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row34_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row35_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row35_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row36_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row37_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row37_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row38_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row38_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row41_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row41_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row42_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row42_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row43_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row43_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row44_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row44_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row45_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row45_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row46_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row46_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row47_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row47_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row48_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row48_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row49_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row49_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row50_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row51_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row51_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row52_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row53_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row53_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row54_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row54_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row55_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row57_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row57_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row58_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row58_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row59_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row61_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row61_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row62_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row62_col2,#T_b7f477ba_345f_11eb_a73f_0242ac110002row63_col1,#T_b7f477ba_345f_11eb_a73f_0242ac110002row64_col1{\n",
       "            background-color:  lightskyblue;\n",
       "        }</style><table id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >feature</th>        <th class=\"col_heading level0 col1\" >export</th>        <th class=\"col_heading level0 col2\" >train</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row0_col0\" class=\"data row0 col0\" >ac_cumsum</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row0_col1\" class=\"data row0 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row0_col2\" class=\"data row0 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row1_col0\" class=\"data row1 col0\" >ac_cumsum_content_id</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row1_col1\" class=\"data row1 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row1_col2\" class=\"data row1 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row2_col0\" class=\"data row2 col0\" >ac_cumsum_part</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row2_col1\" class=\"data row2 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row2_col2\" class=\"data row2 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row3_col0\" class=\"data row3 col0\" >ac_cumsum_pct</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row3_col1\" class=\"data row3 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row3_col2\" class=\"data row3 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row4_col0\" class=\"data row4 col0\" >ac_cumsum_pct_content_id</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row4_col1\" class=\"data row4 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row4_col2\" class=\"data row4 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row5_col0\" class=\"data row5 col0\" >ac_cumsum_pct_part</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row5_col1\" class=\"data row5 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row5_col2\" class=\"data row5 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row6_col0\" class=\"data row6 col0\" >ac_cumsum_pct_session</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row6_col1\" class=\"data row6 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row6_col2\" class=\"data row6 col2\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row7_col0\" class=\"data row7 col0\" >ac_cumsum_pct_tag_0</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row7_col1\" class=\"data row7 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row7_col2\" class=\"data row7 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row8_col0\" class=\"data row8 col0\" >ac_cumsum_pct_tags</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row8_col2\" class=\"data row8 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row9_col0\" class=\"data row9 col0\" >ac_cumsum_pct_upto</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row9_col2\" class=\"data row9 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row10_col0\" class=\"data row10 col0\" >ac_cumsum_session</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row10_col1\" class=\"data row10 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row10_col2\" class=\"data row10 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row11_col0\" class=\"data row11 col0\" >ac_cumsum_tag_0</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row11_col1\" class=\"data row11 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row11_col2\" class=\"data row11 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row12_col0\" class=\"data row12 col0\" >ac_cumsum_tags</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row12_col1\" class=\"data row12 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row12_col2\" class=\"data row12 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row13_col0\" class=\"data row13 col0\" >ac_cumsum_upto</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row13_col1\" class=\"data row13 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row13_col2\" class=\"data row13 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row14_col0\" class=\"data row14 col0\" >aic_cumsum</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row14_col1\" class=\"data row14 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row14_col2\" class=\"data row14 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row15_col0\" class=\"data row15 col0\" >aic_cumsum_content_id</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row15_col1\" class=\"data row15 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row15_col2\" class=\"data row15 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row16_col0\" class=\"data row16 col0\" >aic_cumsum_part</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row16_col1\" class=\"data row16 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row16_col2\" class=\"data row16 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row17_col0\" class=\"data row17 col0\" >aic_cumsum_session</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row17_col1\" class=\"data row17 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row17_col2\" class=\"data row17 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row18_col0\" class=\"data row18 col0\" >aic_cumsum_tag_0</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row18_col1\" class=\"data row18 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row18_col2\" class=\"data row18 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row19_col0\" class=\"data row19 col0\" >aic_cumsum_tags</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row19_col1\" class=\"data row19 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row19_col2\" class=\"data row19 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row20_col0\" class=\"data row20 col0\" >aic_cumsum_upto</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row20_col1\" class=\"data row20 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row20_col2\" class=\"data row20 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row21_col0\" class=\"data row21 col0\" >bundle_id</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row21_col1\" class=\"data row21 col1\" >False</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row21_col2\" class=\"data row21 col2\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row22_col0\" class=\"data row22 col0\" >answered_correctly</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row22_col1\" class=\"data row22 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row22_col2\" class=\"data row22 col2\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row23_col0\" class=\"data row23 col0\" >content_id</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row23_col1\" class=\"data row23 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row23_col2\" class=\"data row23 col2\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row24_col0\" class=\"data row24 col0\" >content_type_id</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row24_col1\" class=\"data row24 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row24_col2\" class=\"data row24 col2\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row25_col0\" class=\"data row25 col0\" >correct_answer</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row25_col1\" class=\"data row25 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row25_col2\" class=\"data row25 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row26_col0\" class=\"data row26 col0\" >fold</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row26_col1\" class=\"data row26 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row26_col2\" class=\"data row26 col2\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row27_col0\" class=\"data row27 col0\" >lecture_id</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row27_col1\" class=\"data row27 col1\" >False</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row27_col2\" class=\"data row27 col2\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row28_col0\" class=\"data row28 col0\" >lectures_cumcnt</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row28_col1\" class=\"data row28 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row28_col2\" class=\"data row28 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row29_col0\" class=\"data row29 col0\" >lectures_cumcnt_part</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row29_col1\" class=\"data row29 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row29_col2\" class=\"data row29 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row30_col0\" class=\"data row30 col0\" >lectures_cumcnt_session</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row30_col1\" class=\"data row30 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row30_col2\" class=\"data row30 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row31_col0\" class=\"data row31 col0\" >lectures_cumcnt_tag_0</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row31_col1\" class=\"data row31 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row31_col2\" class=\"data row31 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row32_col0\" class=\"data row32 col0\" >lectures_cumcnt_tags</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row32_col1\" class=\"data row32 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row32_col2\" class=\"data row32 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row33_col0\" class=\"data row33 col0\" >part</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row33_col1\" class=\"data row33 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row33_col2\" class=\"data row33 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row34_col0\" class=\"data row34 col0\" >part_correct_pct</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row34_col1\" class=\"data row34 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row34_col2\" class=\"data row34 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row35_col0\" class=\"data row35 col0\" >pqet_sec</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row35_col1\" class=\"data row35 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row35_col2\" class=\"data row35 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row36_col0\" class=\"data row36 col0\" >pqet_sec_rollavg</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row36_col1\" class=\"data row36 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row36_col2\" class=\"data row36 col2\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row37_col0\" class=\"data row37 col0\" >prior_question_elapsed_time</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row37_col1\" class=\"data row37 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row37_col2\" class=\"data row37 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row38_col0\" class=\"data row38 col0\" >prior_question_had_explanation</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row38_col1\" class=\"data row38 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row38_col2\" class=\"data row38 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row39_col0\" class=\"data row39 col0\" >ql_id</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row39_col1\" class=\"data row39 col1\" >False</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row39_col2\" class=\"data row39 col2\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row40_col0\" class=\"data row40 col0\" >question_id</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row40_col1\" class=\"data row40 col1\" >False</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row40_col2\" class=\"data row40 col2\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row41_col0\" class=\"data row41 col0\" >question_id_correct_pct</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row41_col1\" class=\"data row41 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row41_col2\" class=\"data row41 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row42_col0\" class=\"data row42 col0\" >r_cumcnt</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row42_col1\" class=\"data row42 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row42_col2\" class=\"data row42 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row43_col0\" class=\"data row43 col0\" >r_cumcnt_clip</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row43_col1\" class=\"data row43 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row43_col2\" class=\"data row43 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row44_col0\" class=\"data row44 col0\" >r_cumcnt_content_id</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row44_col1\" class=\"data row44 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row44_col2\" class=\"data row44 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row45_col0\" class=\"data row45 col0\" >r_cumcnt_part</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row45_col1\" class=\"data row45 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row45_col2\" class=\"data row45 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row46_col0\" class=\"data row46 col0\" >r_cumcnt_session</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row46_col1\" class=\"data row46 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row46_col2\" class=\"data row46 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row47_col0\" class=\"data row47 col0\" >r_cumcnt_tag_0</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row47_col1\" class=\"data row47 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row47_col2\" class=\"data row47 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row48_col0\" class=\"data row48 col0\" >r_cumcnt_tags</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row48_col1\" class=\"data row48 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row48_col2\" class=\"data row48 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row49_col0\" class=\"data row49 col0\" >r_cumcnt_upto</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row49_col1\" class=\"data row49 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row49_col2\" class=\"data row49 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row50_col0\" class=\"data row50 col0\" >row_id</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row50_col1\" class=\"data row50 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row50_col2\" class=\"data row50 col2\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row51_col0\" class=\"data row51 col0\" >session</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row51_col1\" class=\"data row51 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row51_col2\" class=\"data row51 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row52_col0\" class=\"data row52 col0\" >session_minute_max</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row52_col1\" class=\"data row52 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row52_col2\" class=\"data row52 col2\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row53_col0\" class=\"data row53 col0\" >tag_0</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row53_col1\" class=\"data row53 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row53_col2\" class=\"data row53 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row54_col0\" class=\"data row54 col0\" >tag_0_correct_pct</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row54_col1\" class=\"data row54 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row54_col2\" class=\"data row54 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row55_col0\" class=\"data row55 col0\" >tags</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row55_col1\" class=\"data row55 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row55_col2\" class=\"data row55 col2\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row56_col0\" class=\"data row56 col0\" >tags_array</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row56_col1\" class=\"data row56 col1\" >False</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row56_col2\" class=\"data row56 col2\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row57\" class=\"row_heading level0 row57\" >57</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row57_col0\" class=\"data row57 col0\" >tags_code</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row57_col1\" class=\"data row57 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row57_col2\" class=\"data row57 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row58\" class=\"row_heading level0 row58\" >58</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row58_col0\" class=\"data row58 col0\" >tags_correct_pct</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row58_col1\" class=\"data row58 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row58_col2\" class=\"data row58 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row59\" class=\"row_heading level0 row59\" >59</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row59_col0\" class=\"data row59 col0\" >task_container_id</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row59_col1\" class=\"data row59 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row59_col2\" class=\"data row59 col2\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row60\" class=\"row_heading level0 row60\" >60</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row60_col0\" class=\"data row60 col0\" >task_container_id_orig</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row60_col1\" class=\"data row60 col1\" >False</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row60_col2\" class=\"data row60 col2\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row61\" class=\"row_heading level0 row61\" >61</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row61_col0\" class=\"data row61 col0\" >timestamp</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row61_col1\" class=\"data row61 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row61_col2\" class=\"data row61 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row62\" class=\"row_heading level0 row62\" >62</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row62_col0\" class=\"data row62 col0\" >ts_minute</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row62_col1\" class=\"data row62 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row62_col2\" class=\"data row62 col2\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row63\" class=\"row_heading level0 row63\" >63</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row63_col0\" class=\"data row63 col0\" >user_answer</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row63_col1\" class=\"data row63 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row63_col2\" class=\"data row63 col2\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002level0_row64\" class=\"row_heading level0 row64\" >64</th>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row64_col0\" class=\"data row64 col0\" >user_id</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row64_col1\" class=\"data row64 col1\" >True</td>\n",
       "                        <td id=\"T_b7f477ba_345f_11eb_a73f_0242ac110002row64_col2\" class=\"data row64 col2\" >False</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa77defffd0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <hide-input>\n",
    "def show_features():\n",
    "    df_features = pd.DataFrame(features).T.reset_index()\n",
    "    df_features.columns = ['feature', 'export', 'train']\n",
    "    df_features\n",
    "\n",
    "    def highlight_true(s):\n",
    "        return ['background-color: lightskyblue' if v else '' for v in s]\n",
    "    return df_features.style.apply(highlight_true, subset=['export', 'train'])\n",
    "show_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "reut9PmcjuRV"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "def get_dmatrices(folds_train=None, folds_val=None, matrix=xgb.DMatrix):\n",
    "    y_train_col = ['answered_correctly']\n",
    "\n",
    "    x_train_cols = columns_train\n",
    "\n",
    "    mask_train = df_train.fold.isin(folds_train)\n",
    "    mask_valid = df_train.fold.isin(folds_val)\n",
    "\n",
    "    train_matrix = matrix(data=df_train.loc[mask_train][x_train_cols],\n",
    "                            label=df_train.loc[mask_train][y_train_col])\n",
    "\n",
    "    valid_matrix = matrix(data=df_train.loc[mask_valid][x_train_cols],\n",
    "                            label=df_train.loc[mask_valid][y_train_col])\n",
    "    \n",
    "    return {'train_matrix': train_matrix,\n",
    "            'valid_matrix': valid_matrix,\n",
    "            'folds_train': folds_train,\n",
    "            'folds_val': folds_val\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5gUTzNtjuRX"
   },
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "t6AeR8lBjuRX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/calebeverett/riiid-2020/b3652e7760184450b32a3e76e2a42142\n",
      "\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/calebeverett/riiid-2020/b3652e7760184450b32a3e76e2a42142\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     train_auc [683]     : (0.759246, 0.785574)\n",
      "COMET INFO:     train_error [683]   : (0.259728, 0.274447)\n",
      "COMET INFO:     train_logloss [683] : (0.516462, 0.667239)\n",
      "COMET INFO:     valid_auc [683]     : (0.756933, 0.768625)\n",
      "COMET INFO:     valid_error [683]   : (0.269355, 0.27594)\n",
      "COMET INFO:     valid_logloss [683] : (0.53246, 0.667508)\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     begin_iteration : 1\n",
      "COMET INFO:     booster         : gbtree\n",
      "COMET INFO:     df_train_len    : 25510100\n",
      "COMET INFO:     end_iteration   : 1000\n",
      "COMET INFO:     eta             : 0.1\n",
      "COMET INFO:     eval_metric     : ['logloss', 'error', 'auc']\n",
      "COMET INFO:     feature_names   : ['ac_cumsum', 'ac_cumsum_content_id', 'ac_cumsum_part', 'ac_cumsum_pct', 'ac_cumsum_pct_content_id', 'ac_cumsum_pct_part', 'ac_cumsum_pct_tag_0', 'ac_cumsum_pct_tags', 'ac_cumsum_pct_upto', 'ac_cumsum_session', 'ac_cumsum_tag_0', 'ac_cumsum_tags', 'ac_cumsum_upto', 'aic_cumsum', 'aic_cumsum_content_id', 'aic_cumsum_part', 'aic_cumsum_session', 'aic_cumsum_tag_0', 'aic_cumsum_tags', 'aic_cumsum_upto', 'correct_answer', 'lectures_cumcnt', 'lectures_cumcnt_part', 'lectures_cumcnt_session', 'lectures_cumcnt_tag_0', 'lectures_cumcnt_tags', 'part', 'part_correct_pct', 'pqet_sec', 'prior_question_elapsed_time', 'prior_question_had_explanation', 'question_id_correct_pct', 'r_cumcnt', 'r_cumcnt_clip', 'r_cumcnt_content_id', 'r_cumcnt_part', 'r_cumcnt_session', 'r_cumcnt_tag_0', 'r_cumcnt_tags', 'r_cumcnt_upto', 'session', 'tag_0', 'tag_0_correct_pct', 'tags_code', 'tags_correct_pct', 'timestamp', 'ts_minute']\n",
      "COMET INFO:     feature_types   : ['int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'i', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int', 'int']\n",
      "COMET INFO:     folds_train     : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "COMET INFO:     folds_val       : [18, 19]\n",
      "COMET INFO:     grow_policy     : lossguide\n",
      "COMET INFO:     max_bin         : 512\n",
      "COMET INFO:     max_depth       : 10\n",
      "COMET INFO:     objective       : binary:logistic\n",
      "COMET INFO:     rank            : 1\n",
      "COMET INFO:     sampling_method : gradient_based\n",
      "COMET INFO:     tree_method     : gpu_hist\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     code                     : 1 (37 KB)\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (201 KB)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO:     model graph              : 1\n",
      "COMET INFO:     model-element            : 1\n",
      "COMET INFO:     notebook                 : 1\n",
      "COMET INFO:     os packages              : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Uploading stats to Comet before program termination (may take several seconds)\n",
      "COMET INFO: Waiting for completion of the file uploads (may take several seconds)\n",
      "COMET INFO: Still uploading\n"
     ]
    }
   ],
   "source": [
    "# <hide-output>\n",
    "params = {\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 10,\n",
    "    'max_bin': 512,\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'grow_policy': 'lossguide',\n",
    "    'sampling_method': 'gradient_based',\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': ['logloss', 'error', 'auc']\n",
    "}\n",
    "\n",
    "def train_model(params=params, train_matrix=None, valid_matrix=None,\n",
    "                folds_train=None, folds_val=None, verbose_eval=True, comet_summary=1):\n",
    "    if NOT_KAGGLE:\n",
    "        experiment = Experiment(display_summary_level=comet_summary)\n",
    "        # experiment.set_name('with gap_minute_avg')\n",
    "        experiment.log_parameter('folds_train', folds_train)\n",
    "        experiment.log_parameter('folds_val', folds_val)\n",
    "        experiment.log_parameter('df_train_len', len(df_train))\n",
    "\n",
    "    evals_result = {}\n",
    "    model = xgb.train(params=params, dtrain=train_matrix, num_boost_round=1000,\n",
    "                    evals=[(train_matrix, 'train'), (valid_matrix, 'valid')],\n",
    "                    evals_result=evals_result, early_stopping_rounds=20,\n",
    "                    verbose_eval=verbose_eval)\n",
    "\n",
    "    if NOT_KAGGLE:\n",
    "        exp_key = experiment.get_key()\n",
    "        model.save_model(f'{exp_key}.xgb')\n",
    "        experiment.log_model(exp_key, f'{exp_key}.xgb')\n",
    "        experiment.end()\n",
    "        \n",
    "    return model, exp_key\n",
    "    \n",
    "exps = {}\n",
    "\n",
    "folds_list = [\n",
    "    {'folds_train': folds[0:-2], 'folds_val': folds[-2:]}\n",
    "]\n",
    "\n",
    "for folds_run in folds_list:\n",
    "    model, exp_key = train_model(params, **get_dmatrices(**folds_run),\n",
    "                                 verbose_eval=False, comet_summary=1)\n",
    "    exps[exp_key] = model.attributes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fe7JKQf0juRZ"
   },
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qPTKUFJMjuRZ"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "def get_evals_df(evals_result):\n",
    "    evals_list = []\n",
    "    for k,v in evals_result.items():\n",
    "        for j,u in v.items():\n",
    "            evals_list.extend([{'epoch': i,\n",
    "                                'split': k,\n",
    "                                'metric': j,\n",
    "                                'result': r} for i,r in enumerate(u)])\n",
    "    \n",
    "    df_evals = (pd.DataFrame(evals_list).set_index(['split', 'metric', 'epoch'])\n",
    "                .unstack('metric'))\n",
    "    df_evals.columns = df_evals.columns.get_level_values(1)\n",
    "    df_evals.columns.name = None\n",
    "    \n",
    "    return df_evals.reset_index()\n",
    "\n",
    "df_evals = get_evals_df(evals_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oa7h74fSjuRb"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "df_evals.plot(x='epoch', y=['auc', 'logloss'],\n",
    "              facet_col='split', title='Learning Curves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iIK9aXVpjuRd"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "imps = model.get_score(importance_type='gain').items()\n",
    "df_imp = pd.DataFrame(imps, columns=['feature', 'importance'])\n",
    "df_imp = df_imp.set_index('feature').sort_values('importance', ascending=False)\n",
    "df_imp.plot(kind='bar', y='importance', title='Feature Importances - Gain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwBUgoWhI6hu"
   },
   "source": [
    "## Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i5eKbbg7vkpy"
   },
   "outputs": [],
   "source": [
    "git.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qbLXXiPkQAt6"
   },
   "outputs": [],
   "source": [
    "cat_cols = ['correct_answer', 'part', 'tag_0']\n",
    "\n",
    "lgbm_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': ['binary_logloss', 'binary_error', 'auc'],\n",
    "    'device': 'gpu'\n",
    "}\n",
    "\n",
    "folds_run = {'folds_train': folds[0:9], 'folds_val': folds[9:]}\n",
    "\n",
    "matrices = get_dmatrices(folds_train=folds_run['folds_train'],\n",
    "                         folds_val=folds_run['folds_val'],\n",
    "                         matrix=lgb.Dataset)\n",
    "\n",
    "\n",
    "experiment = Experiment(display_summary_level=1)\n",
    "experiment.log_parameter('folds_train', matrices['folds_train'])\n",
    "experiment.log_parameter('folds_val', matrices['folds_val'])\n",
    "experiment.log_parameter('df_train_len', len(df_train))\n",
    "\n",
    "evals_result = {}\n",
    "model = lgb.train(\n",
    "    params = lgbm_params,\n",
    "    train_set = matrices['train_matrix'],\n",
    "    valid_sets = matrices['valid_matrix'],\n",
    "    num_boost_round = 1000,\n",
    "    verbose_eval = 10,\n",
    "    evals_result = evals_result,\n",
    "    early_stopping_rounds = 10,\n",
    "    categorical_feature = [columns_train.index(c) for c in cat_cols],\n",
    "    feature_name = columns_train\n",
    "    )\n",
    "\n",
    "experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t49TzqNPq5pg"
   },
   "source": [
    "## Prepare Prediction Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXZ10jxVjuRf"
   },
   "source": [
    "### Download Final Users State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3eJlJt1FjuRg"
   },
   "outputs": [],
   "source": [
    "# <hide-input><hide-output>\n",
    "%%time\n",
    "\n",
    "if False:    \n",
    "    query = Q.select_user_final_state(table_id='train', no_upto=10)\n",
    "    df_users = bqh.get_df_query_gcs(query, dtypes=dtypes, file_format='csv')\n",
    "    df_users.to_pickle('df_users.pkl')\n",
    "    bucket.blob('df_users.pkl').upload_from_filename('df_users.pkl')\n",
    "else:\n",
    "    bucket.blob('df_users.pkl').download_to_filename('df_users.pkl')\n",
    "    df_users = pd.read_pickle('df_users.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ccdPfyJ8WrhH"
   },
   "outputs": [],
   "source": [
    "df_users[df_users.user_id == 8623]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xok_9xlD7c0H"
   },
   "source": [
    "### Download Final User-Content State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RUVdoI5V8FD1"
   },
   "outputs": [],
   "source": [
    "# <hide-input><hide-output>\n",
    "%%time\n",
    "\n",
    "if False:\n",
    "    query = Q.select_user_content_final_state(table_id='train')\n",
    "    df_users_content = bqh.get_df_query_gcs(query, dtypes=dtypes)\n",
    "    df_users_content.to_pickle('df_users_content.pkl')\n",
    "    bucket.blob('df_users_content.pkl').upload_from_filename('df_users_content.pkl')\n",
    "else:\n",
    "    bucket.blob('df_users_content.pkl').download_to_filename('df_users_content.pkl')\n",
    "    df_users_content = pd.read_pickle(f'df_users_content.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEdnHEoEbKNa"
   },
   "outputs": [],
   "source": [
    "df_users_content[(df_users_content.user_id == 8623) & (df_users_content.content_id == 763)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVS-PapIkfPG"
   },
   "source": [
    "### Download Final User-Tags State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-v6vBK7vkdzf"
   },
   "outputs": [],
   "source": [
    "# <hide-input><hide-output>\n",
    "if False:\n",
    "    query = Q.select_users_tag_final_state(table_id='train')\n",
    "    df_users_tag = bqh.get_df_query_gcs(query, dtypes=dtypes, file_format='csv')\n",
    "    df_users_tag.to_pickle('df_users_tag.pkl')\n",
    "    bucket.blob('df_users_tag.pkl').upload_from_filename('df_users_tag.pkl')\n",
    "else:\n",
    "    bucket.blob('df_users_tag.pkl').download_to_filename('df_users_tag.pkl')\n",
    "    df_users_tag = pd.read_pickle('df_users_tag.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m_RJCpSxcrGy"
   },
   "outputs": [],
   "source": [
    "df_users_tag[(df_users_tag.user_id == 8623) & (df_users_tag.tag == 69)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWvj0FYpjuRj"
   },
   "source": [
    "### Download Content-Tags Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mG3gRUwmjuRl"
   },
   "outputs": [],
   "source": [
    "# <hide-input><hide-output>\n",
    "if False:\n",
    "    # only 14k rows, so it downloaded directly from BigQuery\n",
    "    df_content_tags = bqh.get_df_table('content_tags', max_results=None, dtypes=None)\n",
    "    df_questions = df_content_tags[df_content_tags.lecture_id.isna()]\n",
    "    del df_questions['lecture_id']\n",
    "    df_questions = df_questions.astype({d: t for d, t in dtypes.items() if d in df_questions.columns})\n",
    "    df_lectures = df_content_tags[df_content_tags.question_id.isna()][['ql_id', 'lecture_id', 'part', 'tags', 'tags_array', 'tag_0']]\n",
    "    df_lectures = df_lectures.astype({d: t for d, t in dtypes.items() if d in df_lectures.columns})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NH5WM3VjuRn"
   },
   "source": [
    "## Update Kaggle Submission Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6GV4lXzRKvE8"
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    exps={}\n",
    "    e = 'ce9d161813854d3287b80a38b6968193'\n",
    "    exp = APIExperiment(previous_experiment=e)\n",
    "    exp.download_model(e)\n",
    "    e_model = xgb.Booster(model_file=f'{e}.xgb')\n",
    "    exps[e] = e_model.attributes()\n",
    "\n",
    "    columns_train = json.loads(exp.get_parameters_summary(\n",
    "        parameter='feature_names')['valueCurrent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0B8sbkGjuRo"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "if False:\n",
    "    Path(KAGGLE_SUBMIT_DATASET).mkdir(exist_ok=True)\n",
    "\n",
    "    with open(f'{KAGGLE_SUBMIT_DATASET}/columns.json', 'w') as cj:\n",
    "            json.dump(columns_train, cj)\n",
    "\n",
    "    with open(f'{KAGGLE_SUBMIT_DATASET}/dtypes.json', 'w') as dj:\n",
    "            json.dump(dtypes, dj)\n",
    "    \n",
    "    with open(f'{KAGGLE_SUBMIT_DATASET}/models.json', 'w') as mj:\n",
    "        json.dump(exps, mj)\n",
    "\n",
    "    for m in exps:\n",
    "        src = Path(f'{m}.xgb')\n",
    "        (KAGGLE_SUBMIT_DATASET/src).write_bytes(src.read_bytes())\n",
    "    \n",
    "    df_files = {\n",
    "        'df_users.pkl': df_users,\n",
    "        'df_users_content.pkl': df_users_content,\n",
    "        'df_users_tag.pkl': df_users_tag,\n",
    "        'df_questions.pkl': df_questions,\n",
    "        'df_lectures.pkl': df_lectures\n",
    "    }\n",
    "\n",
    "    for file_path, df in df_files.items():\n",
    "        if Path(file_path).exists():\n",
    "            (Path(f'{KAGGLE_SUBMIT_DATASET}/{file_path}')\n",
    "            .write_bytes(Path(file_path).read_bytes()))\n",
    "        else:\n",
    "            df.to_pickle(f'{KAGGLE_SUBMIT_DATASET}/{file_path}')\n",
    "            \n",
    "    kaggle_id = f\"{os.getenv('KAGGLE_USERNAME')}/{KAGGLE_SUBMIT_DATASET}\"\n",
    "    \n",
    "    metadata = {\n",
    "        \"licenses\": [{\"name\": \"CC0-1.0\"}],\n",
    "        \"id\": kaggle_id,\n",
    "        \"title\": KAGGLE_SUBMIT_DATASET\n",
    "    }\n",
    "\n",
    "    with open(f'{KAGGLE_SUBMIT_DATASET}/dataset-metadata.json', 'w') as f:\n",
    "        json.dump(metadata, f)\n",
    "            \n",
    "    if kaggle_api.dataset_status(kaggle_id):\n",
    "        kaggle_api.dataset_create_version(KAGGLE_SUBMIT_DATASET,\n",
    "                                          version_notes='update dataset',\n",
    "                                          delete_old_versions=True,\n",
    "                                          dir_mode='tar',\n",
    "                                          quiet=True\n",
    "                                         )\n",
    "    else:\n",
    "        kaggle_api.dataset_create_new(KAGGLE_SUBMIT_DATASET,\n",
    "                                      dir_mode='tar', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-RK0etUwdw3"
   },
   "source": [
    "## Push Kernel to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XoJcDapFwhCT"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "if NOT_KAGGLE:\n",
    "    if False:\n",
    "        \n",
    "        code_file = 'riiid-2020.ipynb'\n",
    "        with open(DRIVE/REPO/code_file, 'r') as nb:\n",
    "            nb_json = json.load(nb)       \n",
    "        \n",
    "        for i, cell in enumerate(nb_json['cells']):\n",
    "            if cell['cell_type'] == 'code':\n",
    "                \n",
    "                # update show/hide code cells\n",
    "                for h in ['input', 'output']:c\n",
    "                    if cell['source'][0].find(f'<hide-{h}') > 1:\n",
    "                        nb_json['cells'][i]['metadata'].update({f'_kg_hide-{h}': True})\n",
    "                    else:\n",
    "                        nb_json['cells'][i]['metadata'].pop(f'_kg_hide-{h}', None)\n",
    "\n",
    "                # add modules as cells\n",
    "                if len(cell['source']) == 1:\n",
    "                    groups = re.search(r'(?<=\\<include-)(.*?)(?=\\>)', cell['source'][0])\n",
    "                    \n",
    "                    if groups:\n",
    "                        with open(DRIVE/REPO/groups.group(0), 'r') as m:\n",
    "                            nb_json['cells'][i]['source'] = m.readlines() + nb_json['cells'][i]['source']    \n",
    "\n",
    "\n",
    "        if Path(code_file).exists():\n",
    "            Path(code_file).unlink()\n",
    "        \n",
    "        with open(f'{code_file}', 'w') as f:\n",
    "            json.dump(nb_json, f)\n",
    "\n",
    "        data = {'id': 'calebeverett/riiid-bigquery-xgboost-end-to-end',\n",
    "                        'title': 'RIIID: BigQuery-XGBoost End-to-End',\n",
    "                        'code_file': code_file,\n",
    "                        'language': 'python',\n",
    "                        'kernel_type': 'notebook',\n",
    "                        'is_private': 'false',\n",
    "                        'enable_gpu': 'true',\n",
    "                        'enable_internet': 'true',\n",
    "                        'dataset_sources': [],\n",
    "                        'competition_sources': ['riiid-test-answer-prediction'],\n",
    "                        'kernel_sources': []}\n",
    "        \n",
    "        with open('kernel-metadata.json', 'w') as f:\n",
    "            json.dump(data, f)\n",
    "\n",
    "        kaggle_api.kernels_push('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HN5k3_N-juRp"
   },
   "source": [
    "## Submit From Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGXlGXmjjuRq"
   },
   "source": [
    "* Go to [RIIID Submit](https://www.kaggle.com/calebeverett/riiid-submit), fork and update to reference your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmHGcMTtEDZi"
   },
   "source": [
    "## Push Submit Kernel to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5oJG61mU9ES"
   },
   "outputs": [],
   "source": [
    "dataset_status = None\n",
    "while dataset_status != 'ready':\n",
    "    time.sleep(1)\n",
    "    dataset_status = kaggle_api.datasets_status(CONFIG.get('KAGGLE_USERNAME'),\n",
    "                                                KAGGLE_SUBMIT_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iO6rPRH6EQJZ"
   },
   "outputs": [],
   "source": [
    "# <hide-input>\n",
    "if NOT_KAGGLE:\n",
    "    if True:\n",
    "        submit_kernel = 'calebeverett/riiid-submit-private'\n",
    "        kernel_path = Path('submit_kernel')\n",
    "        kaggle_api.kernels_pull('calebeverett/riiid-submit-private', kernel_path, metadata=True)\n",
    "        kaggle_api.kernels_push(kernel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4xRZVyHWFLT"
   },
   "outputs": [],
   "source": [
    "kaggle_api.kernels_status('calebeverett/riiid-submit-private')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VVtvmvU3s9T"
   },
   "source": [
    "## Update Experiments with Submission Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qfp_-0ZMN7xT"
   },
   "outputs": [],
   "source": [
    "kaggle_api.kernels_list(mine=True, competition='riiid-test-answer-prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ct8kmjFx30aw"
   },
   "outputs": [],
   "source": [
    "kaggle_api.competition_submissions_cli('riiid-test-answer-prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDpy6AmWx_U8"
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    exp_keys = ['021c51e26e1e4a0795414429c0d0ea21', '1b2178bca8ae40ffb869adc2b948cfe3', '9351f247da8949eba061967c2642376e']\n",
    "\n",
    "    for exp_key in exp_keys:\n",
    "        exp = APIExperiment(previous_experiment=exp_key)\n",
    "        exp.log_other('submitted', True)\n",
    "        exp.log_other('submitDate', '2020-11-19 06:39:18')\n",
    "        exp.log_other('publicScore', 0.772)\n",
    "        exp.log_other('kernelUrl', 'https://www.kaggle.com/calebeverett/riiid-submit-private?scriptVersionId=47216065')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "8QCO0cr_juQA",
    "cs6bXr35juQM",
    "BjTuu8CJjuQT",
    "QhPzQmvUjuQV",
    "GOpOrtr9juQY",
    "Ouoo1oQCjuQm",
    "CfKY_WsvjuQp",
    "YTG_h2a2juQy",
    "zO6GM_CLjuQ5"
   ],
   "machine_shape": "hm",
   "name": "riiid-2020.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/CalebEverett/riiid-2020/blob/master/riiid-2020.ipynb",
     "timestamp": 1604714801726
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
>>>>>>> cf1dc7a7be9bc166a01222581ac361e9aa3f9dd5
